import { Hono } from 'hono'
import { cors } from 'hono/cors'
import { AIGatewayService } from './services/ai-gateway'
import { getArticleAnalysisPrompt } from './prompts/articleAnalysis'
import { IntelligenceService } from './services/intelligence'
import { CloudflareEnv, ChatResponse } from './types'

type HonoEnv = {
  Bindings: CloudflareEnv & {
    AI: Ai
  }
}

const app = new Hono<HonoEnv>()

app.use('*', cors({
  origin: '*',
  allowMethods: ['GET', 'POST', 'PUT', 'DELETE', 'OPTIONS'],
  allowHeaders: ['Content-Type', 'Authorization'],
}))

// ÊöÇÊó∂Ê≥®ÈáäÊéâlogger‰∏≠Èó¥‰ª∂ÔºåÂõ†‰∏∫ÂÆÉÂèØËÉΩÂπ≤Êâ∞JSONÂìçÂ∫î
// app.use('*', logger())

// =============================================================================
// ÈÄöÁî®Â∑•ÂÖ∑ÂáΩÊï∞
// =============================================================================

/**
 * ÁîüÊàêÈÄöÁî®ËØ∑Ê±ÇÂÖÉÊï∞ÊçÆÔºåÂáèÂ∞ëÈáçÂ§ç‰ª£Á†Å
 */
function createRequestMetadata(c: any) {
  return {
    requestId: `req_${Date.now()}_${Math.random().toString(36).substring(2, 11)}`,
    timestamp: Date.now(),
    userAgent: c.req.header('user-agent') || 'unknown',
    ipAddress: c.req.header('cf-connecting-ip') || c.req.header('x-forwarded-for') || 'unknown'
  }
}

// =============================================================================
// Health Check
// =============================================================================

app.get('/health', (c) => {
  return c.json({ 
    status: 'healthy', 
    timestamp: new Date().toISOString(),
    service: 'meridian-ai-worker'
  })
})

// =============================================================================  
// Embedding Generation
// =============================================================================

app.post('/meridian/embeddings/generate', async (c) => {
  try {
    const body = await c.req.json()
    
    // È™åËØÅËØ∑Ê±ÇÂèÇÊï∞ - ÊîØÊåÅÂ§öÁßçËæìÂÖ•Ê†ºÂºè
    const hasTextInput = body.text && (
      (typeof body.text === 'string' && body.text.trim().length > 0) ||
      (Array.isArray(body.text) && body.text.length > 0)
    )
    const hasQueryContextInput = body.query && body.contexts && Array.isArray(body.contexts)
    
    if (!hasTextInput && !hasQueryContextInput) {
      return c.json({ 
        success: false,
        error: 'Invalid request: either text (string or array) or query+contexts is required'
      }, 400)
    }

    // ÂàõÂª∫AI Gateway Service
    const aiGatewayService = new AIGatewayService(c.env)
    
    // ÊûÑÂª∫ÂµåÂÖ•ËØ∑Ê±Ç
    const embeddingRequest: any = {
      capability: 'embedding',
      provider: body.options?.provider || 'workers-ai',
      model: body.options?.model || '@cf/baai/bge-small-en-v1.5',
      // Ê∑ªÂä†Âü∫Á°ÄmetadataÊù•Á°Æ‰øùÊÄßËÉΩËøΩË∏™
      metadata: createRequestMetadata(c)
    }
    
    // Ê†πÊçÆËæìÂÖ•Á±ªÂûãËÆæÁΩÆËØ∑Ê±ÇÂèÇÊï∞
    if (hasQueryContextInput) {
      // BGE-M3 Êü•ËØ¢Âíå‰∏ä‰∏ãÊñáÊ†ºÂºè
      embeddingRequest.query = body.query
      embeddingRequest.contexts = body.contexts
      embeddingRequest.truncate_inputs = body.truncate_inputs
    } else {
      // Ê†áÂáÜÊñáÊú¨ÂµåÂÖ•Ê†ºÂºè
      embeddingRequest.input = body.text
    }

    // ÈÄöËøáAI GatewayÂ§ÑÁêÜÂµåÂÖ•ËØ∑Ê±Ç
    const result = await aiGatewayService.embed(embeddingRequest)
    
    // Á°Æ‰øùÁªìÊûúÊòØÂµåÂÖ•ÂìçÂ∫îÁ±ªÂûã
    if (result.capability !== 'embedding') {
      throw new Error('Unexpected response type from embedding service')
    }
    
    // ËÆ°ÁÆóÂÆûÈôÖÁöÑÂµåÂÖ•Áª¥Â∫¶
    let dimensions = 0
    let dataLength = 0
    
    if (result.data && Array.isArray(result.data) && result.data.length > 0) {
      dataLength = result.data.length
      // Ëé∑ÂèñÁ¨¨‰∏Ä‰∏™ÂµåÂÖ•ÂêëÈáèÁöÑÁª¥Â∫¶
      const firstEmbedding = result.data[0]?.embedding
      if (Array.isArray(firstEmbedding)) {
        dimensions = firstEmbedding.length
      }
    }
    
    return c.json({
      success: true,
      data: result.data,
      model: result.model,
      dimensions: dimensions,
      data_points: dataLength,
      text_length: Array.isArray(body.text) ? body.text.join(' ').length : (body.text?.length || 0),
      metadata: {
        provider: result.provider,
        model: result.model,
        processingTime: result.processingTime || result.metadata?.performance?.latency?.totalLatency,
        cached: result.cached,
        performance: result.metadata?.performance
      }
    })
  } catch (error: any) {
    console.error('Embedding generation error:', error)
    return c.json({ 
      success: false,
      error: 'Failed to generate embedding',
      details: error.message,
      stack: error.stack
    }, 500)
  }
})

// =============================================================================
// Article Analysis
// =============================================================================

// ÈÄöÁî®ÊñáÁ´†ÂàÜÊûêÂáΩÊï∞
async function analyzeArticle(c: any, returnFormat: 'detailed' | 'workflow' = 'detailed') {
  const body = await c.req.json()
  
  // È™åËØÅËØ∑Ê±ÇÂèÇÊï∞
  if (!body.title || !body.content) {
    return c.json({ 
      success: false,
      error: 'Invalid request: title and content are required'
    }, 400)
  }

  // ÂàõÂª∫AI Gateway Service
  const aiGatewayService = new AIGatewayService(c.env)
  
  // ÊûÑÂª∫ÂàÜÊûêÊèêÁ§∫
  const prompt = getArticleAnalysisPrompt(body.title, body.content)
  
  // ÊûÑÂª∫ËÅäÂ§©ËØ∑Ê±Ç
  const chatRequest = {
    capability: 'chat' as const,
    messages: [{ role: 'user' as const, content: prompt }],
    provider: body.options?.provider || 'google-ai-studio',
    model: body.options?.model || 'gemini-2.0-flash',
    temperature: 0.1,
    max_tokens: 8000,
    // Ê∑ªÂä†Âü∫Á°ÄmetadataÊù•Á°Æ‰øùÊÄßËÉΩËøΩË∏™
    metadata: createRequestMetadata(c)
  }

  // ÈÄöËøáAI GatewayÂ§ÑÁêÜÂàÜÊûêËØ∑Ê±Ç
  const result = await aiGatewayService.chat(chatRequest)
  
  // Á°Æ‰øùÁªìÊûúÊòØËÅäÂ§©ÂìçÂ∫îÁ±ªÂûã
  if (result.capability !== 'chat') {
    throw new Error('Unexpected response type from chat service')
  }
  
  const chatResult = result as ChatResponse
  
  // Â∞ùËØïËß£ÊûêJSONÂìçÂ∫î
  let analysisResult
  try {
    const responseText = chatResult.choices?.[0]?.message?.content || ''
    const jsonMatch = responseText.match(/```json\n([\s\S]*?)\n```/)
    if (jsonMatch) {
      analysisResult = JSON.parse(jsonMatch[1])
    } else {
      // Â∞ùËØïÁõ¥Êé•Ëß£ÊûêÊï¥‰∏™ÂìçÂ∫î
      analysisResult = JSON.parse(responseText)
    }
  } catch (parseError) {
    if (returnFormat === 'workflow') {
      // Â∑•‰ΩúÊµÅÊ†ºÂºèÈúÄË¶ÅÈªòËÆ§ÂÄº
      analysisResult = {
        language: 'unknown',
        primary_location: 'unknown',
        completeness: 'PARTIAL_USEFUL',
        content_quality: 'OK',
        event_summary_points: [],
        thematic_keywords: [],
        topic_tags: [],
        key_entities: [],
        content_focus: []
      }
    } else {
      // ËØ¶ÁªÜÊ†ºÂºèÂåÖÂê´ÂéüÂßãÂìçÂ∫î
      analysisResult = { 
        error: 'Êó†Ê≥ïËß£ÊûêAIÂìçÂ∫î', 
        raw_response: chatResult.choices?.[0]?.message?.content || ''
      }
    }
  }
  
  // Ê†πÊçÆËøîÂõûÊ†ºÂºèÊûÑÂª∫ÂìçÂ∫î
  if (returnFormat === 'workflow') {
    return c.json({
      success: true,
      data: analysisResult,
      metadata: {
        model_used: chatResult.model,
        provider: chatResult.provider,
        total_tokens: chatResult.usage?.total_tokens || 0,
        processingTime: chatResult.processingTime,
        cached: chatResult.cached
      }
    })
  } else {
    return c.json({
      success: true,
      result: analysisResult,
      usage: chatResult.usage,
      metadata: {
        provider: chatResult.provider,
        model: chatResult.model,
        processingTime: chatResult.processingTime,
        cached: chatResult.cached
      }
    })
  }
}

// ËØ¶ÁªÜÂàÜÊûêÁ´ØÁÇπ
app.post('/meridian/analyze', async (c) => {
  try {
    return await analyzeArticle(c, 'detailed')
  } catch (error: any) {
    console.error('Analysis error:', error)
    return c.json({ 
      success: false,
      error: 'Failed to analyze article',
      details: error.message
    }, 500)
  }
})

// ProcessArticlesÂ∑•‰ΩúÊµÅ‰ΩøÁî®ÁöÑË∑ØÂæÑ
app.post('/meridian/article/analyze', async (c) => {
  try {
    return await analyzeArticle(c, 'workflow')
  } catch (error: any) {
    console.error('Analysis error:', error)
    return c.json({ 
      success: false,
      error: 'Failed to analyze article',
      details: error.message
    }, 500)
  }
})

// =============================================================================
// Chat API
// =============================================================================

app.post('/meridian/chat', async (c) => {
  try {
    const body = await c.req.json()
    
    // È™åËØÅËØ∑Ê±ÇÂèÇÊï∞
    if (!body.messages || !Array.isArray(body.messages)) {
      return c.json({ 
        success: false,
        error: 'Invalid request: messages array is required'
      }, 400)
    }

    // È™åËØÅÊ∂àÊÅØÊ†ºÂºè
    for (const message of body.messages) {
      if (!message.role || !message.content) {
        return c.json({ 
          success: false,
          error: 'Invalid message format: role and content are required'
        }, 400)
      }
      if (!['system', 'user', 'assistant'].includes(message.role)) {
        return c.json({ 
          success: false,
          error: 'Invalid role: must be system, user, or assistant'
        }, 400)
      }
    }

    // ÂàõÂª∫AI Gateway Service
    const aiGatewayService = new AIGatewayService(c.env)
    
    // ÊûÑÂª∫ËÅäÂ§©ËØ∑Ê±Ç
    const chatRequest = {
      capability: 'chat' as const,
      messages: body.messages,
      provider: body.options?.provider,
      model: body.options?.model,
      temperature: body.options?.temperature || 0.7,
      max_tokens: body.options?.max_tokens || 1000,
      stream: body.options?.stream || false,
      metadata: createRequestMetadata(c)
    }

    // Â§ÑÁêÜËÅäÂ§©ËØ∑Ê±Ç
    const result = await aiGatewayService.chat(chatRequest)
    
    // Á°Æ‰øùÁªìÊûúÊòØChatResponseÁ±ªÂûã
    if (result.capability !== 'chat') {
      throw new Error('Unexpected response type from chat service')
    }
    
    const chatResult = result as ChatResponse
    
    return c.json({
      success: true,
      data: {
        id: chatResult.id,
        choices: chatResult.choices,
        usage: chatResult.usage,
        model: chatResult.model,
        provider: chatResult.provider
      },
      metadata: {
        provider: chatResult.provider,
        model: chatResult.model,
        processingTime: chatResult.processingTime,
        cached: chatResult.cached
      }
    })
  } catch (error: any) {
    console.error('Chat error:', error)
    return c.json({ 
      success: false,
      error: 'Failed to process chat request',
      details: error.message
    }, 500)
  }
})

// ÊîØÊåÅÊµÅÂºèËÅäÂ§©ÂìçÂ∫îÁöÑÁ´ØÁÇπ
app.post('/meridian/chat/stream', async (c) => {
  try {
    const body = await c.req.json()
    
    // È™åËØÅËØ∑Ê±ÇÂèÇÊï∞
    if (!body.messages || !Array.isArray(body.messages)) {
      return c.json({ 
        success: false,
        error: 'Invalid request: messages array is required'
      }, 400)
    }

    // ÂàõÂª∫AI Gateway Service
    const aiGatewayService = new AIGatewayService(c.env)
    
    // ÊûÑÂª∫ÊµÅÂºèËÅäÂ§©ËØ∑Ê±Ç
    const chatRequest = {
      capability: 'chat' as const,
      messages: body.messages,
      provider: body.options?.provider,
      model: body.options?.model,
      temperature: body.options?.temperature || 0.7,
      max_tokens: body.options?.max_tokens || 1000,
      stream: true,
      metadata: createRequestMetadata(c)
    }

    // Â§ÑÁêÜÊµÅÂºèËÅäÂ§©ËØ∑Ê±Ç
    const result = await aiGatewayService.chat(chatRequest)
    
    // Á°Æ‰øùÁªìÊûúÊòØChatResponseÁ±ªÂûã
    if (result.capability !== 'chat') {
      throw new Error('Unexpected response type from chat service')
    }
    
    const chatResult = result as ChatResponse
    
    // ÂØπ‰∫éÊµÅÂºèÂìçÂ∫îÔºåËøîÂõûÁâπÊÆäÊ†ºÂºè
    return c.json({
      success: true,
      data: {
        id: chatResult.id,
        choices: chatResult.choices,
        usage: chatResult.usage,
        model: chatResult.model,
        provider: chatResult.provider
      },
      metadata: {
        provider: chatResult.provider,
        model: chatResult.model,
        streaming: true,
        processingTime: chatResult.processingTime,
        cached: chatResult.cached
      }
    })
  } catch (error: any) {
    console.error('Stream chat error:', error)
    return c.json({ 
      success: false,
      error: 'Failed to process stream chat request',
      details: error.message
    }, 500)
  }
})

// =============================================================================
// Intelligence Analysis
// =============================================================================

app.post('/meridian/intelligence/analyze-story', async (c) => {
  try {
    const body = await c.req.json()
    
    // Ê£ÄÊü•ËæìÂÖ•Ê†ºÂºèÔºöÊîØÊåÅÊñ∞ÁöÑÂ∑•‰ΩúÊµÅÊ†ºÂºè (story + cluster) ÂíåÊóßÁöÑÊ†ºÂºè
    if (body.story && body.cluster) {
      // Êñ∞ÁöÑÂ∑•‰ΩúÊµÅÊ†ºÂºèÔºö{story: {...}, cluster: {...}}
      const { story, cluster } = body
      
      console.log(`[Intelligence] ÂàÜÊûêÂ∑•‰ΩúÊµÅÊ†ºÂºèÊïÖ‰∫ã: ${story.storyId}, ËÅöÁ±ª‰∏≠ÊñáÁ´†Êï∞: ${cluster.articles?.length || 0}`)
      
      // È™åËØÅclusterÊï∞ÊçÆÂÆåÊï¥ÊÄß
      if (!cluster.articles || !Array.isArray(cluster.articles) || cluster.articles.length === 0) {
        console.warn(`[Intelligence] ËÅöÁ±ªÊï∞ÊçÆÊó†ÊïàÊàñ‰∏∫Á©∫: ${JSON.stringify(cluster)}`)
        return c.json({
          success: false,
          error: 'ËÅöÁ±ª‰∏≠Ê≤°ÊúâÊúâÊïàÁöÑÊñáÁ´†Êï∞ÊçÆ'
        }, 400)
      }
      
      // ËΩ¨Êç¢‰∏∫IntelligenceServiceÊúüÊúõÁöÑÊ†ºÂºèÔºåÂπ∂Êèê‰æõfallbackÂÜÖÂÆπ
      const transformedRequest = {
        title: story.analysis?.summary || `ÊïÖ‰∫ã ${story.storyId}`,
        articles_ids: cluster.articles.map((a: any) => a.id),
        articles_data: cluster.articles.map((a: any) => {
          // Êèê‰æõÊõ¥‰∏∞ÂØåÁöÑfallbackÂÜÖÂÆπ
          const content = a.content || 
                         a.title || 
                         `ÊñáÁ´†ÂÜÖÂÆπÊöÇ‰∏çÂèØÁî®„ÄÇÊ†áÈ¢ò: ${a.title || 'Êó†Ê†áÈ¢ò'}„ÄÇURL: ${a.url || 'Êó†ÈìæÊé•'}`;
          
          return {
            id: a.id,
            title: a.title || 'Êó†Ê†áÈ¢ò',
            url: a.url || '',
            content: content,
            publishDate: a.publish_date?.toISOString?.() || 
                        (typeof a.publish_date === 'string' ? a.publish_date : new Date().toISOString())
          }
        })
      }
      
             console.log(`[Intelligence] ËΩ¨Êç¢ÂêéÁöÑËØ∑Ê±ÇÊï∞ÊçÆ - ÊñáÁ´†Êï∞: ${transformedRequest.articles_data.length}`)
       transformedRequest.articles_data.forEach((article: any, index: number) => {
         console.log(`[Intelligence] ÊñáÁ´† ${index + 1}: ID=${article.id}, Ê†áÈ¢ò="${article.title}", ÂÜÖÂÆπÈïøÂ∫¶=${article.content.length}`)
       })
      
      const intelligenceService = new IntelligenceService(c.env)
      const result = await intelligenceService.analyzeStory(transformedRequest)
      
      // Ê£ÄÊü•ÂàÜÊûêÁªìÊûúÂπ∂Êèê‰æõfallback
      let analysisData
      if (result.analysis && typeof result.analysis === 'object') {
        if (result.analysis.status === 'parsing_failed' && result.analysis.fallback_analysis) {
          // ‰ΩøÁî®fallbackÂàÜÊûê
          analysisData = result.analysis.fallback_analysis
        } else {
          // ‰ΩøÁî®Ê≠£Â∏∏ÂàÜÊûêÁªìÊûú
          analysisData = {
            overview: result.analysis.title || result.analysis.executiveSummary || result.story_title,
            key_developments: result.analysis.executiveSummary ? [result.analysis.executiveSummary] : 
                            result.analysis.key_developments || ['ÂàÜÊûêÊ≠£Âú®Â§ÑÁêÜ‰∏≠'],
            stakeholders: result.analysis.stakeholders || ['AIÂàÜÊûêÁ≥ªÁªü'],
            implications: result.analysis.implications || ['ÈúÄË¶ÅËøõ‰∏ÄÊ≠•Ê∑±ÂÖ•ÂàÜÊûê'],
            outlook: result.analysis.storyStatus || result.analysis.outlook || 'ÂèëÂ±ï‰∏≠'
          }
        }
      } else {
        // ÂÆåÂÖ®fallback
        analysisData = {
          overview: story.analysis?.summary || `ÊïÖ‰∫ã ${story.storyId}`,
          key_developments: story.analysis?.key_themes || ['ÂàÜÊûêÂ§ÑÁêÜ‰∏≠'],
          stakeholders: ['AIÂàÜÊûêÁ≥ªÁªü'],
          implications: ['ÈúÄË¶ÅËøõ‰∏ÄÊ≠•ÂàÜÊûê'],
          outlook: 'Â§ÑÁêÜ‰∏≠'
        }
      }
      
      return c.json({
        success: true,
        data: analysisData,
        metadata: {
          ...result.metadata,
          fallback_used: !result.analysis || result.analysis.status === 'parsing_failed',
          articles_processed: transformedRequest.articles_data.length
        }
      })
    } else {
      // ÂéüÊúâÊ†ºÂºèÔºöÁõ¥Êé•‰º†ÈÄíÁªôIntelligenceService
      const intelligenceService = new IntelligenceService(c.env)
      const result = await intelligenceService.analyzeStory(body)
      return c.json(result)
    }
  } catch (error: any) {
    console.error('Intelligence analysis error:', error)
    return c.json({ 
      success: false,
      error: error.message,
      details: error.stack
    }, 500)
  }
})

// =============================================================================
// Backend Integration Status
// =============================================================================

app.get('/meridian/status', (c) => {
  try {
    const aiGatewayService = new AIGatewayService(c.env)
    
    return c.json({ 
      status: 'active',
      service: 'meridian-ai-worker',
      timestamp: new Date().toISOString(),
      endpoints: {
        // Ê†∏ÂøÉ‰∏öÂä°Á´ØÁÇπ (Backend Â∑•‰ΩúÊµÅ‰ΩøÁî®)
        article_analysis: '/meridian/article/analyze',
        embedding_generation: '/meridian/embeddings/generate', 
        intelligence_analysis: '/meridian/intelligence/analyze-story',
        // ÈÄöÁî®Á´ØÁÇπ
        chat: '/meridian/chat',
        chat_stream: '/meridian/chat/stream',
        health: '/health',
        test: '/test'
      },
      integration: {
        backend_workflows: ['processArticles'],
        ai_providers: aiGatewayService.getAvailableProviders(),
        capabilities: ['chat', 'embedding', 'intelligence'],
        version: '1.3.0'
      },
      workflow_integration: {
        'processArticles.workflow.ts': {
          endpoints_used: ['/meridian/article/analyze', '/meridian/embeddings/generate'],
          description: 'ÊñáÁ´†ÂÜÖÂÆπÂ§ÑÁêÜÂíåÂµåÂÖ•ÁîüÊàê'
        }
      }
    })
  } catch (error) {
    return c.json({
      status: 'error',
      service: 'meridian-ai-worker', 
      error: error instanceof Error ? error.message : 'Unknown error',
      timestamp: new Date().toISOString()
    }, 500)
  }
})

// =============================================================================
// Data Endpoints
// =============================================================================

// =============================================================================
// Legacy Data Endpoints (Moved to Backend)
// =============================================================================
// Êï∞ÊçÆÊü•ËØ¢Âíå‰øùÂ≠òÂäüËÉΩÂ∑≤ËøÅÁßªÂà∞ backend ÊúçÂä°ÔºåAI Worker ‰∏ìÊ≥®‰∫é AI ËÉΩÂäõ

// =============================================================================
// Service Testing & Monitoring
// =============================================================================

// AI Worker Ê†∏ÂøÉÂäüËÉΩÊµãËØïÁ´ØÁÇπ
app.get('/test-ai-capabilities', async (c) => {
  try {
    console.log('[AI Capabilities Test] ÂºÄÂßãÊµãËØïAI WorkerÊ†∏ÂøÉÂäüËÉΩ')
    
    const aiGatewayService = new AIGatewayService(c.env)
    
    // ÊµãËØïÂµåÂÖ•ÁîüÊàê - Áõ¥Êé•Ë∞ÉÁî®ÊúçÂä°
    let embeddingResult: any = null
    let embeddingError: any = null
    try {
      const embeddingRequest = {
        capability: 'embedding' as const,
        provider: 'workers-ai',
        model: '@cf/baai/bge-small-en-v1.5',
        input: "ÊµãËØïÂµåÂÖ•ÁîüÊàêÂäüËÉΩ",
        metadata: createRequestMetadata(c)
      }
      
      const embeddingResponse = await aiGatewayService.embed(embeddingRequest)
      if (embeddingResponse.capability === 'embedding') {
        embeddingResult = {
          status: 'success',
          dimensions: embeddingResponse.data?.[0]?.embedding?.length || 0,
          provider: embeddingResponse.provider
        }
      } else {
        throw new Error('Unexpected response type from embedding service')
      }
    } catch (error: any) {
      embeddingError = error.message
      embeddingResult = {
        status: 'failed',
        error: error.message,
        dimensions: 0
      }
    }

    // ÊµãËØïÊñáÁ´†ÂàÜÊûê - Áõ¥Êé•Ë∞ÉÁî®AI Gateway
    let analysisResult: any = null
    let analysisError: any = null
    try {
      const analysisRequest = {
        capability: 'chat' as const,
        messages: [{ 
          role: 'user' as const, 
          content: getArticleAnalysisPrompt("AIÊäÄÊúØÂèëÂ±ïË∂ãÂäø", "‰∫∫Â∑•Êô∫ËÉΩÊäÄÊúØÊ≠£Âú®Âø´ÈÄüÂèëÂ±ïÔºåÂú®ÂêÑ‰∏™È¢ÜÂüüÈÉΩÊúâÈáçË¶ÅÂ∫îÁî®„ÄÇ")
        }],
        provider: 'workers-ai',
        model: '@cf/meta/llama-2-7b-chat-int8',
        temperature: 0.1,
        max_tokens: 2000,
        metadata: createRequestMetadata(c)
      }
      
      const analysisResponse = await aiGatewayService.chat(analysisRequest)
      if (analysisResponse.capability === 'chat') {
        analysisResult = {
          status: 'success',
          analysis_completed: true,
          provider: analysisResponse.provider,
          response_length: analysisResponse.choices?.[0]?.message?.content?.length || 0
        }
      } else {
        throw new Error('Unexpected response type from chat service')
      }
    } catch (error: any) {
      analysisError = error.message
      analysisResult = {
        status: 'failed',
        error: error.message,
        analysis_completed: false
      }
    }

    return c.json({
      success: true,
      test_name: 'AI Worker Core Capabilities Test',
      results: {
        embedding_generation: embeddingResult,
        article_analysis: analysisResult
      },
      ai_gateway_status: {
        providers_available: aiGatewayService.getAvailableProviders().length,
        capabilities: ['chat', 'embedding', 'intelligence']
      },
      errors: {
        embedding_error: embeddingError,
        analysis_error: analysisError
      },
      timestamp: new Date().toISOString()
    })
  } catch (error: any) {
    console.error('AI capabilities test error:', error)
    return c.json({
      success: false,
      error: 'Failed to test AI capabilities',
      details: error.message,
      timestamp: new Date().toISOString()
    }, 500)
  }
})

app.get('/test', async (c) => {
  try {
    // ËΩªÈáèÁ∫ßÂäüËÉΩÊµãËØïÔºåÈ™åËØÅ AI Gateway ËøûÈÄöÊÄß
    const aiGatewayService = new AIGatewayService(c.env)
    
    return c.json({
      success: true,
      service: 'meridian-ai-worker',
      message: 'AI Worker service is operational',
      providers: aiGatewayService.getAvailableProviders(),
      capabilities: ['chat', 'embedding', 'intelligence'],
      timestamp: new Date().toISOString()
    })
  } catch (error) {
    console.error('Service test error:', error)
    return c.json({
      success: false,
      error: error instanceof Error ? error.message : 'Unknown error',
      timestamp: new Date().toISOString()
    }, 500)
  }
})

// =============================================================================
// Story Validation and Analysis
// =============================================================================

app.post('/meridian/story/validate', async (c) => {
  try {
    const body = await c.req.json()
    
    // È™åËØÅËØ∑Ê±ÇÂèÇÊï∞
    if (!body.cluster || !body.cluster.articles || !Array.isArray(body.cluster.articles)) {
      return c.json({ 
        success: false,
        error: 'Invalid request: cluster with articles array is required'
      }, 400)
    }

    const { cluster } = body
    console.log(`[Story Validation] È™åËØÅËÅöÁ±ªÔºåÂåÖÂê´ ${cluster.articles.length} ÁØáÊñáÁ´†`)

    // ÊûÑÂª∫ÊñáÁ´†ÂàóË°®Áî®‰∫éLLMÂàÜÊûê (‰∏énotebook‰∏≠ÁöÑprocess_storyÂáΩÊï∞‰∏ÄËá¥)
    const articleList = cluster.articles
      .map((a: any) => `- (#${a.id}) [${a.title}](${a.url})`)
      .join('\n')

    // üÜï Â¢ûÂº∫ÁöÑÊïÖ‰∫ãÈ™åËØÅÊèêÁ§∫ËØç - Êèê‰æõÂÆåÊï¥ÁöÑÈÄèÊòéÂ∫¶‰ø°ÊÅØ
    const validationPrompt = `
# Task
Determine if the following collection of news articles is:
1) A single story - A cohesive narrative where all articles relate to the same central event/situation and its direct consequences
2) A collection of stories - Distinct narratives that should be analyzed separately
3) Pure noise - Random articles with no meaningful pattern
4) No stories - Distinct narratives but none of them have more than 3 articles

# Important clarification
A "single story" can still have multiple aspects or angles. What matters is whether the articles collectively tell one broader narrative where understanding each part enhances understanding of the whole.

# Handling outliers
- For single stories: You can exclude true outliers in an "outliers" array
- For collections: Focus **only** on substantive stories (2+ articles). Ignore one-off articles or noise.

# Title guidelines
- Titles should be purely factual, descriptive and neutral
- Include necessary context (region, countries, institutions involved)
- No editorialization, opinion, or emotional language
- Format: "[Subject] [action/event] in/with [location/context]"

# Transparency Requirements (NEW)
For each story identified, you must provide:
1. **Importance Factors**: Detailed breakdown of why this story got its importance score
2. **Quality Metrics**: Assess coherence, relevance, uniqueness, and timeliness
3. **Reasoning**: Clear explanation of your decision-making process
4. **Confidence**: How confident you are in this assessment (0.0-1.0)
5. **Key Topics**: Main themes and subjects covered in the story

# Input data
Articles (format is (#id) [title](url)):
${articleList}

# Output format
Return your final answer in JSON format with enhanced transparency:
\`\`\`json
{
    "answer": "single_story" | "collection_of_stories" | "pure_noise" | "no_stories",
    "reasoning_process": "Detailed explanation of how you analyzed these articles and reached your conclusion",
    // single_story_start: if answer is "single_story", include the following fields:
    "title": "title of the story",
    "importance": 1-10,
    "importance_factors": {
        "global_significance": 1-10,
        "affected_population": 1-10,
        "economic_impact": 1-10,
        "geopolitical_relevance": 1-10,
        "innovation_factor": 1-10
    },
    "quality_metrics": {
        "coherence": 0.0-1.0,
        "relevance": 0.0-1.0,
        "uniqueness": 0.0-1.0,
        "timeliness": 0.0-1.0
    },
    "reasoning": "Why this story matters and how you determined its importance",
    "confidence": 0.0-1.0,
    "key_topics": ["topic1", "topic2", "topic3"],
    "outliers": []
    // single_story_end
    // collection_of_stories_start: if answer is "collection_of_stories", include the following fields:
    "stories": [
        {
            "title": "title of the story",
            "importance": 1-10,
            "importance_factors": {
                "global_significance": 1-10,
                "affected_population": 1-10,
                "economic_impact": 1-10,
                "geopolitical_relevance": 1-10,
                "innovation_factor": 1-10
            },
            "quality_metrics": {
                "coherence": 0.0-1.0,
                "relevance": 0.0-1.0,
                "uniqueness": 0.0-1.0,
                "timeliness": 0.0-1.0
            },
            "reasoning": "Why this story matters and how you determined its importance",
            "confidence": 0.0-1.0,
            "key_topics": ["topic1", "topic2", "topic3"],
            "articles": []
        }
    ]
    // collection_of_stories_end
}
\`\`\`

Note:
- Always include articles IDs (outliers, articles, etc...) as integers, not strings and never include the # symbol.
- Be thorough in your reasoning - this will help improve the system's transparency.
- Rate importance factors on individual 1-10 scales, then derive overall importance.
- Quality metrics should be precise decimal values reflecting your assessment.
    `.trim()

    // ÂàõÂª∫AI Gateway Service
    const aiGatewayService = new AIGatewayService(c.env)
    
    // ÊûÑÂª∫ËÅäÂ§©ËØ∑Ê±Ç
    const chatRequest = {
      capability: 'chat' as const,
      messages: [{ role: 'user' as const, content: validationPrompt }],
      provider: body.options?.provider || 'google-ai-studio',
      model: body.options?.model || 'gemini-2.0-flash',
      temperature: 0,
      max_tokens: 2000,
      metadata: createRequestMetadata(c)
    }

    // Â§ÑÁêÜÈ™åËØÅËØ∑Ê±Ç
    const result = await aiGatewayService.chat(chatRequest)
    
    // Á°Æ‰øùÁªìÊûúÊòØChatResponseÁ±ªÂûã
    if (result.capability !== 'chat') {
      throw new Error('Unexpected response type from chat service')
    }
    
    const chatResult = result as ChatResponse
    
    // Ëß£ÊûêLLMÂìçÂ∫î
    let responseText = chatResult.choices?.[0]?.message?.content || ''
    
    // ÊèêÂèñJSONÈÉ®ÂàÜ
    if (responseText.includes('```json')) {
      responseText = responseText.split('```json')[1]
      if (responseText.includes('```')) {
        responseText = responseText.split('```')[0]
      }
    }
    
    try {
      const validation = JSON.parse(responseText.trim())
      
      // üÜï Ê†πÊçÆÈ™åËØÅÁªìÊûúÁîüÊàêÊ∏ÖÁêÜÂêéÁöÑÊïÖ‰∫ã - ÂåÖÂê´ÂÆåÊï¥ÈÄèÊòéÂ∫¶‰ø°ÊÅØ
      const cleanedStories = []
      
             if (validation.answer === 'single_story') {
         // Âçï‰∏ÄÊïÖ‰∫ãÔºöËøáÊª§ÂºÇÂ∏∏ÁÇπ
         const validArticleIds = cluster.articles
           .map((a: any) => a.id)
           .filter((id: any) => !validation.outliers?.includes(id))
        
        if (validArticleIds.length >= 2) { // Ëá≥Â∞ëÈúÄË¶Å2ÁØáÊñáÁ´†
          cleanedStories.push({
            id: cluster.id,
            title: validation.title,
            importance: validation.importance,
            // üÜï Â¢ûÂä†ÈÄèÊòéÂ∫¶Â≠óÊÆµ
            importance_factors: validation.importance_factors || {},
            quality_metrics: validation.quality_metrics || {},
            reasoning: validation.reasoning || 'Êú™Êèê‰æõËØ¶ÁªÜÊé®ÁêÜ',
            confidence: validation.confidence || 0,
            key_topics: validation.key_topics || [],
            coherence_score: validation.quality_metrics?.coherence || 0,
            relevance_score: validation.quality_metrics?.relevance || 0,
            uniqueness_score: validation.quality_metrics?.uniqueness || 0,
            timeliness_score: validation.quality_metrics?.timeliness || 0,
            articles: validArticleIds
          })
        }
             } else if (validation.answer === 'collection_of_stories') {
         // ÊïÖ‰∫ãÈõÜÂêàÔºöÂàÜËß£‰∏∫Â§ö‰∏™Áã¨Á´ãÊïÖ‰∫ã
         validation.stories?.forEach((story: any, index: number) => {
           if (story.articles.length >= 2) { // Âè™‰øùÁïôÊúâË∂≥Â§üÊñáÁ´†ÁöÑÊïÖ‰∫ã
             cleanedStories.push({
               id: cluster.id * 1000 + index, // ÁîüÊàêÂîØ‰∏ÄID
               title: story.title,
               importance: story.importance,
               // üÜï Â¢ûÂä†ÈÄèÊòéÂ∫¶Â≠óÊÆµ
               importance_factors: story.importance_factors || {},
               quality_metrics: story.quality_metrics || {},
               reasoning: story.reasoning || 'Êú™Êèê‰æõËØ¶ÁªÜÊé®ÁêÜ',
               confidence: story.confidence || 0,
               key_topics: story.key_topics || [],
               coherence_score: story.quality_metrics?.coherence || 0,
               relevance_score: story.quality_metrics?.relevance || 0,
               uniqueness_score: story.quality_metrics?.uniqueness || 0,
               timeliness_score: story.quality_metrics?.timeliness || 0,
               articles: story.articles
             })
           }
         })
       }
      // pure_noise Âíå no_stories ÊÉÖÂÜµ‰∏ã‰∏çÊ∑ªÂä†‰ªª‰ΩïÊïÖ‰∫ã
      
      console.log(`[Story Validation] ËÅöÁ±ª ${cluster.id} Ëß£ÊûêÊàêÂäüÔºåÁîüÊàê ${cleanedStories.length} ‰∏™Ê∏ÖÁêÜÂêéÁöÑÊïÖ‰∫ã`)
      
      return c.json({
        success: true,
        data: {
          validation_result: validation.answer,
          cleaned_stories: cleanedStories,
          original_cluster_id: cluster.id,
          processed_articles: cluster.articles.length,
          // üÜï Â¢ûÂä†AIÊé®ÁêÜËøáÁ®ãÈÄèÊòéÂ∫¶
          reasoning_process: validation.reasoning_process || 'Êú™Êèê‰æõËØ¶ÁªÜÊé®ÁêÜËøáÁ®ã'
        },
        metadata: {
          provider: chatResult.provider,
          model: chatResult.model,
          processingTime: chatResult.processingTime,
          cached: chatResult.cached
        }
      })
      
         } catch (parseError: any) {
       console.warn(`[Story Validation] JSONËß£ÊûêÂ§±Ë¥•:`, parseError, 'ÂéüÂßãÂìçÂ∫î:', responseText)
       
       // Fallback: Â¶ÇÊûúAIËß£ÊûêÂ§±Ë¥•ÔºåÊèê‰æõÂü∫Êú¨ÁöÑfallback
       console.log(`[Story Validation] ‰ΩøÁî®fallbackÈÄªËæë‰∏∫ËÅöÁ±ª ${cluster.id}`)
       const fallbackStories = []
       
       // Â¶ÇÊûúËÅöÁ±ªÊúâË∂≥Â§üÁöÑÊñáÁ´†ÔºåÂàõÂª∫‰∏Ä‰∏™Âü∫Êú¨ÊïÖ‰∫ã
       if (cluster.articles.length >= 2) {
         const articleIds = cluster.articles.map((a: any) => a.id)
         const primaryTitle = cluster.articles[0]?.title || `ÊïÖ‰∫ãÈõÜÁæ§ ${cluster.id}`
         
         fallbackStories.push({
           id: cluster.id,
           title: primaryTitle,
           importance: 5, // ÈªòËÆ§‰∏≠Á≠âÈáçË¶ÅÊÄß
           articles: articleIds
         })
       }
       
       return c.json({
         success: true,
         data: {
           validation_result: 'fallback_processing',
           cleaned_stories: fallbackStories,
           original_cluster_id: cluster.id,
           processed_articles: cluster.articles.length,
           fallback_used: true,
           parse_error: parseError.message
         },
         metadata: {
           provider: chatResult.provider,
           model: chatResult.model,
           processingTime: chatResult.processingTime,
           cached: chatResult.cached,
           fallback_applied: true
         }
       })
     }
    
  } catch (error: any) {
    console.error('Story validation error:', error)
    return c.json({ 
      success: false,
      error: 'Failed to validate story',
      details: error.message
    }, 500)
  }
})

// =============================================================================
// Final Brief Generation (Âü∫‰∫é reportV5.md)
// =============================================================================

app.post('/meridian/generate-final-brief', async (c) => {
  try {
    const body = await c.req.json()
    
    // È™åËØÅËØ∑Ê±ÇÂèÇÊï∞
    if (!body.analysisData || !Array.isArray(body.analysisData)) {
      return c.json({ 
        success: false,
        error: 'Invalid request: analysisData array is required'
      }, 400)
    }

    console.log(`[Brief Generation] ÂºÄÂßãÁîüÊàêÊúÄÁªàÁÆÄÊä•ÔºåËæìÂÖ•ÂàÜÊûêÊï∞ÊçÆ: ${body.analysisData.length} ‰∏™ÊïÖ‰∫ã`)

    // ÂàõÂª∫AI Gateway Service
    const aiGatewayService = new AIGatewayService(c.env)

    // ÊûÑÂª∫ËÅöÂêàÂàÜÊûêÊï∞ÊçÆ‰∏∫markdownÊ†ºÂºèÔºàÁ±ª‰ººreportV5.md‰∏≠ÁöÑjson_to_markdown_refinedÂáΩÊï∞Ôºâ
    const convertAnalysisToMarkdown = (analysisData: any[]) => {
      let markdown = ''
      
      analysisData.forEach((data, index) => {
        if (index > 0) markdown += '\n---\n\n'
        
        // Ê£ÄÊü•Êï∞ÊçÆÂÆåÊï¥ÊÄß
        if (!data || data.status === 'incomplete') {
          markdown += `# Analysis Incomplete\n\nReason: ${data?.reason || 'Unknown'}\n`
          return
        }

        // Ê†áÈ¢òÂíåÊâßË°åÊëòË¶Å
        const summary = data.executiveSummary || data.overview || 'No summary available.'
        const status = data.storyStatus || 'Status Unknown'
        markdown += `# Key Development Summary: ${summary}\n`
        markdown += `**(Story Status: ${status})**\n\n`

        // ÂÖ≥ÈîÆÊó∂Èó¥Á∫ø‰∫ã‰ª∂
        if (data.timeline && Array.isArray(data.timeline)) {
          markdown += "## Key Timeline Events (High Importance)\n"
                     const highImportanceEvents = data.timeline.filter((event: any) => event.importance === 'High').slice(0, 5)
                     if (highImportanceEvents.length > 0) {
             highImportanceEvents.forEach((event: any) => {
               markdown += `*   **${event.date || 'N/A'}:** ${event.description || 'N/A'}\n`
             })
           } else {
            markdown += "*   *No high-importance events identified in timeline.*\n"
          }
          markdown += "\n"
        }

        // Êï¥‰ΩìÈáçË¶ÅÊÄß
        if (data.significance) {
          markdown += "## Overall Significance\n"
          const assessment = data.significance.assessment || 'N/A'
          const reasoning = data.significance.reasoning || 'No reasoning provided.'
          markdown += `*   **Assessment:** ${assessment}\n`
          markdown += `*   **Reasoning:** ${reasoning}\n\n`
        }

        // Ê†∏ÂøÉ‰∫ãÂÆûÂü∫Á°Ä
        if (data.undisputedKeyFacts && Array.isArray(data.undisputedKeyFacts)) {
          markdown += "## Core Factual Basis (Corroborated)\n"
                     data.undisputedKeyFacts.slice(0, 5).forEach((fact: any) => {
             markdown += `*   ${fact}\n`
           })
          if (data.undisputedKeyFacts.length > 5) {
            markdown += `*   *(Additional facts available)*\n`
          }
          markdown += "\n"
        }

        // ÂÖ≥ÈîÆÂÆû‰Ωì
        if (data.keyEntities?.list && Array.isArray(data.keyEntities.list)) {
          markdown += "## Key Entities Involved\n"
                     data.keyEntities.list.slice(0, 4).forEach((entity: any) => {
             markdown += `*   **${entity.name || 'N/A'} (${entity.type || 'N/A'}):** ${entity.involvement || entity.description || 'N/A'}\n`
           })
          if (data.keyEntities.list.length > 4) {
            markdown += `*   *(Additional entities involved)*\n`
          }
          markdown += "\n"
        }

        // ‰ø°ÊÅØÁº∫Âè£
        if (data.informationGaps && Array.isArray(data.informationGaps)) {
          markdown += "## Critical Information Gaps\n"
                     data.informationGaps.slice(0, 4).forEach((gap: any) => {
             markdown += `*   ${gap}\n`
           })
          if (data.informationGaps.length > 4) {
            markdown += `*   *(Additional gaps identified)*\n`
          }
          markdown += "\n"
        }

        // ËØÑ‰º∞ÊëòË¶Å
        markdown += "## Assessment Summary\n"
        if (data.signalStrength) {
          const assessment = data.signalStrength.assessment || 'N/A'
          markdown += `*   **Signal Strength:** ${assessment}\n`
        } else {
          markdown += "*   Signal Strength: Not Assessed\n"
        }
        markdown += "*   **Note:** Analysis based on sources of varying reliability. Claims from low-reliability sources require caution.\n"
      })
      
      return markdown
    }

    // ËΩ¨Êç¢ÂàÜÊûêÊï∞ÊçÆ‰∏∫markdown
    const storiesMarkdown = convertAnalysisToMarkdown(body.analysisData)

    // Ëé∑ÂèñÂâç‰∏ÄÂ§©ÁöÑÁÆÄÊä•‰∏ä‰∏ãÊñáÔºàÂ¶ÇÊûúÊèê‰æõÔºâ
    let previousContext = ''
    if (body.previousBrief) {
      previousContext = `
## Previous Day's Coverage Context (${body.previousBrief.date || 'Previous Day'})

### ${body.previousBrief.title || 'Previous Brief'}

${body.previousBrief.tldr || 'No previous context available'}
`
    }

    // ÊûÑÂª∫ÁÆÄÊä•ÁîüÊàêÊèêÁ§∫ËØçÔºàÂü∫‰∫éreportV5.mdÁöÑget_brief_promptÂáΩÊï∞Ôºâ
    const briefPrompt = `
hey, i have a bunch of news reports (in random order) derived from detailed analyses of news clusters from the last 30h. could you give me my personalized daily intelligence brief? aim for something comprehensive yet engaging, roughly a 20-30 minute read.

my interests are: significant world news (geopolitics, politics, finance, economics), us news, france news (i'm french/live in france), china news (especially policy, economy, tech - seeking insights often missed in western media), and technology/science (ai/llms, biomed, space, real breakthroughs). also include a section for noteworthy items that don't fit neatly elsewhere.

some context: i built a system that collects/analyzes/compiles news because i was tired of mainstream news that either overwhelms with useless info or misses what actually matters. you're really good at information analysis/writing/etc so i figure by just asking you this i'd get something even better than what presidents get - a focused brief that tells me what's happening, why it matters, and what connections exist that others miss. i value **informed, analytical takes** ‚Äì even if i don't agree with them, they're intellectually stimulating. i want analysis grounded in the facts provided, free from generic hedging or forced political correctness.

your job: go through all the curated news data i've gathered below. analyze **everything** first to identify what *actually* matters before writing. look for:
- actual significance (not just noise/volume)
- hidden patterns and connections between stories
- important developments flying under the radar
- how separate events might be related
- genuinely interesting or impactful stories

**--- CONTEXT FROM PREVIOUS DAY (IF AVAILABLE) ---**
*   You *may* receive a section at the beginning of the curated data titled \`## Previous Day's Coverage Context (YYYY-MM-DD)\`.
*   This section provides a highly condensed list of major stories covered yesterday, using the format: \`[Story Identifier] | [Last Status] | [Key Entities] | [Core Issue Snippet]\`.
*   **How to Use This Context:** Use this list **only** to understand which topics are ongoing and their last known status/theme. This helps ensure continuity and avoid repeating information already covered.
*   **Focus on Today:** Your primary task is to synthesize and analyze **today's developments** based on the main \`<curated_news_data>\`. When discussing a story listed in the previous context, focus on **what is new or has changed today**. Briefly reference the past context *only if essential* for understanding the update (e.g., "Following yesterday's agreement...", "The situation escalated further today when...").
*   **Do NOT simply rewrite or extensively quote the Previous Day's Coverage Context.** Treat it as background memory.
**--- END CONTEXT INSTRUCTIONS ---**

here's the curated data (each section represents an analyzed news cluster; you might need to synthesize across sections):

${previousContext}

<curated_news_data>

${storiesMarkdown}

</curated_news_data>

structure the brief using the sections below, making it feel conversational ‚Äì complete sentences, natural flow, occasional wry commentary where appropriate.
<final_brief>
## what matters now
cover the *up to* 7-8 most significant stories with real insight. for each:
<u>**title that captures the essence**</u>
weave together what happened, why it matters (significance, implications), key context, and your analytical take in natural, flowing paragraphs.
separate paragraphs with linebreaks for readability, but ensure smooth transitions.
blend facts and analysis naturally. **if there isn't much significant development or analysis for a story, keep it brief ‚Äì don't force length.** prioritize depth and insight where warranted.
use **bold** for key specifics (names, places, numbers, orgs), *italics* for important context or secondary details.
offer your **analytical take**: based on the provided facts and context, what are the likely motivations, potential second-order effects, overlooked angles, or inconsistencies? ground this analysis in the data.

## france focus
(i'm french/live in france - ONLY include if there are actual french developments worth reporting)
significant french developments: policy details, key players, economic data, political shifts.

## global landscape
### power & politics
key geopolitical moves, focusing on outcomes and strategic implications, including subtle shifts.

### china monitor
(seeking insights often missed in western media - ONLY include if there are meaningful developments)
meaningful policy shifts, leadership dynamics, economic indicators (with numbers if available), tech developments, social trends.

### economic currents
(ONLY include if there are significant economic developments)
market movements signaling underlying trends, impactful policy decisions, trade/resource developments (with data), potential economic risks or opportunities.

## tech & science developments
(focus on ai/llms, space, biomed, real breakthroughs - ONLY include if there are actual breakthroughs, not minor product updates)
actual breakthroughs, notable ai/llm advancements, significant space news, key scientific progress. separate signal from noise.

## noteworthy & under-reported
(combine under-reported significance and carte blanche - ONLY include if there are genuinely interesting items)
important stories flying under the radar, emerging patterns with specific indicators, slow-burning developments, or other interesting items you think i should see (up to 5 items max).

## positive developments
(ONLY include if there are genuinely positive developments with measurable outcomes - do NOT force content here)
actual progress with measurable outcomes, effective solutions, verifiable improvements.
</final_brief>

use the:
\`\`\`

<u>**title that captures the essence**</u>
paragraph

paragraph

...

\`\`\`
for all sections.

make sure everything inside the <final_brief></final_brief> tags is the actual brief content itself. any/all "hey, here is the brief" or "hope you enjoyed today's brief" should either not be included or be before/after the <final_brief></final_brief> tags.

**final instructions:**
*   always enclose the brief inside <final_brief></final_brief> tags.
*   use lowercase by default like i do. complete sentences please.
*   this is for my eyes only - be direct and analytical.
*   **source reliability:** the input data is derived from analyses that assessed source reliability. use this implicit understanding ‚Äì give more weight to information from reliable sources and treat claims originating solely from known low-reliability/propaganda sources with appropriate caution in your analysis and 'take'. explicitly mentioning source reliability isn't necessary unless a major contradiction hinges on it.
*   **writing style:** aim for the tone of an extremely well-informed, analytical friend with a dry wit and access to incredible information processing. be insightful, engaging, and respect my time. make complex topics clear without oversimplifying. integrate facts, significance, and your take naturally.
*   **leverage your strengths:** process all the info, spot cross-domain patterns, draw on relevant background knowledge (history, economics, etc.), explain clearly, and provide that grounded-yet-insightful analytical layer.

give me the brief i couldn't get before ai - one that combines human-like insight with superhuman information processing.
    `.trim()

    // Á≥ªÁªüÊèêÁ§∫ËØçÔºàÂü∫‰∫éreportV5.mdÔºâ
    const systemPrompt = `
Adopt the persona of an exceptionally well-informed, highly analytical, and slightly irreverent intelligence briefer. Imagine you have near-instant access to and processing power for vast amounts of global information, combined with a sharp, insightful perspective and a dry wit. You're communicating directly and informally with a smart, curious individual who values grounded analysis but dislikes corporate speak, hedging, and forced neutrality.

**Your core stylistic goals are:**

1.  **Tone:** Conversational, direct, and engaging. Use lowercase naturally, as if speaking or writing informally to a trusted peer. Avoid stiff formality, bureaucratic language, or excessive caution. Be chill, but maintain intellectual rigor.
2.  **Analytical Voice:** Prioritize insightful analysis over mere summarization. Go beyond stating facts to explain *why* they matter, connect disparate events, identify underlying patterns, assess motivations, and explore potential implications (second-order effects). Offer a clear, grounded "take" on developments. Don't be afraid to call out inconsistencies or highlight underappreciated angles, always backing it up with the logic derived from the provided information.
3.  **Wit & Personality:** Embrace a dry, clever wit. Humor, sarcasm, or irony should arise *naturally* from the situation or the absurdity of events. Pointing out the obvious when it's funny is fine. **Crucially: Do not force humor, be cringe, or undermine the gravity of serious topics like human suffering.** Wit should enhance insight, not detract from it.
4.  **Language:** Use clear, concise language. Vary sentence structure for natural flow. Occasional relevant slang or shorthand is acceptable if it fits the informal tone naturally, but prioritize clarity. Ensure analysis is sharp and commentary is insightful, not just filler.

**Think of yourself as:** The user's personal "Q" (from James Bond) combined with a sharp geopolitical analyst ‚Äì someone with unparalleled information access who can cut through the noise, connect the dots, and deliver the essential insights with a bit of personality and zero tolerance for BS.

**Relationship to Main Prompt:** This system prompt defines *how* you should write and analyze. Follow the specific content structure, formatting, and topic instructions provided in the main user prompt separately. Your analysis and 'take' should always be grounded in the information provided in the main prompt's \`<curated_news_data>\` section.

Your ultimate goal is to deliver the kind of insightful, personalized, and engaging intelligence brief that wasn't possible before AI ‚Äì combining superhuman data processing with a distinct, analytical, and trustworthy (even if slightly cynical) voice.
    `.trim()

    // ÊûÑÂª∫ËÅäÂ§©ËØ∑Ê±Ç
    const chatRequest = {
      capability: 'chat' as const,
      messages: [
        { role: 'system' as const, content: systemPrompt },
        { role: 'user' as const, content: briefPrompt }
      ],
      provider: body.options?.provider || 'google-ai-studio',
      model: body.options?.model || 'gemini-2.0-flash',
      temperature: 0.7,
      max_tokens: 16000,
      metadata: createRequestMetadata(c)
    }

    console.log(`[Brief Generation] Ë∞ÉÁî®LLMÁîüÊàêÁÆÄÊä•Ôºå‰ΩøÁî®Ê®°Âûã: ${chatRequest.model}`)

    // ÈÄöËøáAI GatewayÂ§ÑÁêÜÁÆÄÊä•ÁîüÊàêËØ∑Ê±Ç
    const result = await aiGatewayService.chat(chatRequest)
    
    // Á°Æ‰øùÁªìÊûúÊòØËÅäÂ§©ÂìçÂ∫îÁ±ªÂûã
    if (result.capability !== 'chat') {
      throw new Error('Unexpected response type from chat service')
    }
    
    const chatResult = result as ChatResponse
    
    // ÊèêÂèñÁÆÄÊä•ÂÜÖÂÆπ
    let briefText = chatResult.choices?.[0]?.message?.content || ''
    
    // ÊèêÂèñ <final_brief> Ê†áÁ≠æÂÜÖÁöÑÂÜÖÂÆπ
    if (briefText.includes('<final_brief>')) {
      briefText = briefText.split('<final_brief>')[1]
      if (briefText.includes('</final_brief>')) {
        briefText = briefText.split('</final_brief>')[0]
      }
    }
    
    briefText = briefText.trim()

    console.log(`[Brief Generation] ÁÆÄÊä•ÁîüÊàêÊàêÂäüÔºåÈïøÂ∫¶: ${briefText.length} Â≠óÁ¨¶`)

    // ÂêåÊó∂ÁîüÊàêÁÆÄÊä•Ê†áÈ¢òÔºàÂü∫‰∫éreportV5.mdÁöÑbrief_title_promptÔºâ
    const titlePrompt = `
<brief>
${briefText}
</brief>

create a title for the brief. construct it using the main topics. it should be short/punchy/not clickbaity etc. make sure to not use "short text: longer text here for some reason" i HATE it, under no circumstance should there be colons in the title. make sure it's not too vague/generic either bc there might be many stories. maybe don't focus on like restituting what happened in the title, just do like the major entities/actors/things that happened. like "[person A], [thing 1], [org B] & [person O]" etc. try not to use verbs. state topics instead of stating topics + adding "shakes world order". always use lowercase.

return exclusively a JSON object with the following format:
\`\`\`json
{
    "title": "string"
}
\`\`\`
    `.trim()

    const titleRequest = {
      capability: 'chat' as const,
      messages: [{ role: 'user' as const, content: titlePrompt }],
      provider: 'google-ai-studio',
      model: 'gemini-2.0-flash',
      temperature: 0.0,
      max_tokens: 1000,
      metadata: createRequestMetadata(c)
    }

    const titleResult = await aiGatewayService.chat(titleRequest)
    let briefTitle = 'daily intelligence brief'
    
    if (titleResult.capability === 'chat') {
      const titleChatResult = titleResult as ChatResponse
      let titleText = titleChatResult.choices?.[0]?.message?.content || ''
      
      // ÊèêÂèñJSON
      if (titleText.includes('```json')) {
        titleText = titleText.split('```json')[1]
        if (titleText.includes('```')) {
          titleText = titleText.split('```')[0]
        }
      }
      
      try {
        const titleData = JSON.parse(titleText.trim())
        briefTitle = titleData.title || briefTitle
      } catch (error) {
        console.warn('[Brief Generation] Ê†áÈ¢òËß£ÊûêÂ§±Ë¥•Ôºå‰ΩøÁî®ÈªòËÆ§Ê†áÈ¢ò')
      }
    }

    console.log(`[Brief Generation] ÁîüÊàêÁöÑÊ†áÈ¢ò: "${briefTitle}"`)

    return c.json({
      success: true,
      data: {
        title: briefTitle,
        content: briefText,
        metadata: {
          sections_processed: body.analysisData.length,
          content_length: briefText.length,
          has_previous_context: !!body.previousBrief,
          model_used: chatResult.model,
          provider: chatResult.provider,
          generation_time: chatResult.processingTime,
          total_tokens: chatResult.usage?.total_tokens || 0
        }
      },
      usage: {
        brief_generation: chatResult.usage,
        title_generation: titleResult.capability === 'chat' ? (titleResult as ChatResponse).usage : undefined
      }
    })

  } catch (error: any) {
    console.error('Brief generation error:', error)
    return c.json({ 
      success: false,
      error: 'Failed to generate final brief',
      details: error.message
    }, 500)
  }
})

export default app
