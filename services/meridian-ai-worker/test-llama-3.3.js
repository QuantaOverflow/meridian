#!/usr/bin/env node

const AI_WORKER_URL = 'http://localhost:8786';
const LLAMA_33_MODEL = '@cf/meta/llama-3.3-70b-instruct-fp8-fast';

async function testRequest(endpoint, data, description) {
  console.log(`\nğŸ§ª æµ‹è¯•: ${description}`);
  console.log(`ğŸ“ ç«¯ç‚¹: ${endpoint}`);
  
  try {
    const response = await fetch(`${AI_WORKER_URL}${endpoint}`, {
      method: 'POST',
      headers: { 'Content-Type': 'application/json' },
      body: JSON.stringify(data)
    });
    
    const result = await response.json();
    
    if (result.success) {
      console.log(`âœ… æˆåŠŸ (${response.status})`);
      if (result.metadata?.model === LLAMA_33_MODEL) {
        console.log(`ğŸ¯ ä½¿ç”¨äº† Llama 3.3 70B æ¨¡å‹`);
      }
      if (result.metadata?.processingTime) {
        console.log(`â±ï¸  å¤„ç†æ—¶é—´: ${result.metadata.processingTime}ms`);
      }
      console.log(`ğŸ“Š å“åº”æ•°æ®: ${JSON.stringify(result.data).substring(0, 200)}...`);
    } else {
      console.log(`âŒ å¤±è´¥ (${response.status}): ${result.error}`);
    }
  } catch (error) {
    console.log(`ğŸ’¥ è¯·æ±‚é”™è¯¯: ${error.message}`);
  }
}

async function runTests() {
  console.log('ğŸš€ å¼€å§‹æµ‹è¯• Llama 3.3 70B Instruct FP8 Fast æ¨¡å‹é›†æˆ\n');
  
  // æµ‹è¯• 1: åŸºæœ¬èŠå¤©åŠŸèƒ½
  await testRequest('/meridian/chat', {
    messages: [
      { role: 'user', content: 'ä½ å¥½ï¼è¯·ä»‹ç»ä¸€ä¸‹ Llama 3.3 æ¨¡å‹çš„ç‰¹ç‚¹ã€‚' }
    ],
    options: {
      provider: 'workers-ai',
      model: LLAMA_33_MODEL,
      temperature: 0.7,
      max_tokens: 300
    }
  }, 'åŸºæœ¬èŠå¤©åŠŸèƒ½');

  // æµ‹è¯• 2: JSON æ¨¡å¼è¾“å‡º
  await testRequest('/meridian/chat', {
    messages: [
      { 
        role: 'system', 
        content: 'ä½ æ˜¯ä¸€ä¸ª AI æŠ€æœ¯ä¸“å®¶ã€‚è¯·ä»¥ JSON æ ¼å¼å›å¤ï¼ŒåŒ…å«å­—æ®µï¼š{\"model_name\": \"\", \"key_features\": [], \"use_cases\": []}' 
      },
      { 
        role: 'user', 
        content: 'åˆ†æ Llama 3.3 70B Instruct FP8 Fast æ¨¡å‹çš„æŠ€æœ¯ç‰¹ç‚¹å’Œåº”ç”¨åœºæ™¯' 
      }
    ],
    options: {
      provider: 'workers-ai',
      model: LLAMA_33_MODEL,
      temperature: 0.3,
      max_tokens: 500
    }
  }, 'JSON ç»“æ„åŒ–è¾“å‡º');

  // æµ‹è¯• 3: æ–‡ç« åˆ†æï¼ˆåº”è¯¥ä¼˜å…ˆä½¿ç”¨ Llama 3.3ï¼‰
  await testRequest('/meridian/article/analyze', {
    title: 'AI æ¨¡å‹æ€§èƒ½å¯¹æ¯”åˆ†æ',
    content: `éšç€å¤§å‹è¯­è¨€æ¨¡å‹çš„å¿«é€Ÿå‘å±•ï¼Œæ¨¡å‹æ€§èƒ½å’Œæ•ˆç‡æˆä¸ºå…³é”®æŒ‡æ ‡ã€‚Llama 3.3 70B é‡‡ç”¨äº† FP8 é‡åŒ–æŠ€æœ¯ï¼Œ
              åœ¨ä¿æŒé«˜è´¨é‡è¾“å‡ºçš„åŒæ—¶ï¼Œæ˜¾è‘—æå‡äº†æ¨ç†é€Ÿåº¦ã€‚è¯¥æ¨¡å‹æ”¯æŒ 24,000 tokens çš„é•¿ä¸Šä¸‹æ–‡çª—å£ï¼Œ
              é€‚åˆå¤„ç†å¤æ‚çš„æ–‡æ¡£å’Œå¯¹è¯ä»»åŠ¡ã€‚Function calling åŠŸèƒ½ä½¿å…¶èƒ½å¤Ÿä¸å¤–éƒ¨å·¥å…·é›†æˆï¼Œ
              æ‰©å±•äº†åº”ç”¨åœºæ™¯ã€‚ç›¸æ¯”å…¶ä»–åŒç±»æ¨¡å‹ï¼ŒLlama 3.3 åœ¨æˆæœ¬æ•ˆç›Šæ–¹é¢è¡¨ç°å‡ºè‰²ã€‚`
  }, 'æ–‡ç« åˆ†æåŠŸèƒ½');

  // æµ‹è¯• 4: é•¿æ–‡æœ¬å¤„ç†èƒ½åŠ›
  const longText = 'åœ¨äººå·¥æ™ºèƒ½å¿«é€Ÿå‘å±•çš„ä»Šå¤©ï¼Œ'.repeat(100);
  await testRequest('/meridian/chat', {
    messages: [
      { 
        role: 'user', 
        content: `è¯·æ€»ç»“ä»¥ä¸‹é•¿æ–‡æœ¬çš„ä¸»è¦è§‚ç‚¹ï¼š\n\n${longText}` 
      }
    ],
    options: {
      provider: 'workers-ai',
      model: LLAMA_33_MODEL,
      temperature: 0.5,
      max_tokens: 400
    }
  }, 'é•¿æ–‡æœ¬å¤„ç†èƒ½åŠ›');

  // æµ‹è¯• 5: å¤šè½®å¯¹è¯
  await testRequest('/meridian/chat', {
    messages: [
      { role: 'user', content: 'ä»€ä¹ˆæ˜¯ FP8 é‡åŒ–ï¼Ÿ' },
      { role: 'assistant', content: 'FP8é‡åŒ–æ˜¯ä¸€ç§æ¨¡å‹å‹ç¼©æŠ€æœ¯...' },
      { role: 'user', content: 'å®ƒç›¸æ¯” FP16 æœ‰ä»€ä¹ˆä¼˜åŠ¿ï¼Ÿ' }
    ],
    options: {
      provider: 'workers-ai',
      model: LLAMA_33_MODEL,
      temperature: 0.6,
      max_tokens: 300
    }
  }, 'å¤šè½®å¯¹è¯èƒ½åŠ›');

  // æµ‹è¯• 6: ä»£ç ç”Ÿæˆ
  await testRequest('/meridian/chat', {
    messages: [
      { 
        role: 'user', 
        content: 'è¯·ç”Ÿæˆä¸€ä¸ª JavaScript å‡½æ•°ï¼Œç”¨äºè°ƒç”¨ Cloudflare Workers AI API å¹¶å¤„ç† Llama 3.3 æ¨¡å‹çš„å“åº”' 
      }
    ],
    options: {
      provider: 'workers-ai',
      model: LLAMA_33_MODEL,
      temperature: 0.2,
      max_tokens: 600
    }
  }, 'ä»£ç ç”Ÿæˆèƒ½åŠ›');

  console.log('\nğŸ æµ‹è¯•å®Œæˆï¼');
  console.log('\nğŸ“‹ æ€»ç»“:');
  console.log(`â€¢ æ¨¡å‹åç§°: ${LLAMA_33_MODEL}`);
  console.log('â€¢ æ”¯æŒåŠŸèƒ½: èŠå¤©ã€JSONè¾“å‡ºã€æ–‡ç« åˆ†æã€é•¿æ–‡æœ¬å¤„ç†ã€å¤šè½®å¯¹è¯ã€ä»£ç ç”Ÿæˆ');
  console.log('â€¢ ä¸Šä¸‹æ–‡çª—å£: 24,000 tokens');
  console.log('â€¢ å®šä»·: $0.29/M input tokens, $2.25/M output tokens');
  console.log('â€¢ ç‰¹æ€§: FP8é‡åŒ–ã€å¿«é€Ÿæ¨ç†ã€Function callingæ”¯æŒ');
}

// è¿è¡Œæµ‹è¯•
runTests().catch(console.error); 