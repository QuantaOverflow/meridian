#!/usr/bin/env python3
"""
æ¨¡æ‹Ÿæ–‡ç« ç”Ÿæˆå™¨ - ä½¿ç”¨ Meridian AI Worker ç”ŸæˆçœŸå®å†…å®¹
ç”Ÿæˆä¸åŒä¸»é¢˜çš„æ¨¡æ‹Ÿæ–‡ç« ï¼Œç”¨äºæµ‹è¯•MLæœåŠ¡çš„èšç±»åŠŸèƒ½
"""

import asyncio
import httpx
import json
from typing import List, Dict, Any
import time

# AI Worker é…ç½®
AI_WORKER_BASE_URL = "https://meridian-ai-worker.swj299792458.workers.dev"
API_TOKEN = "j+96PlDDJPVI7dAhoxdWfgynQTxqEzf5vnea6wrhKXg="  # å¼€å‘ç¯å¢ƒtoken

# æ–‡ç« ä¸»é¢˜å’Œç›¸åº”çš„ç”Ÿæˆprompt
ARTICLE_TOPICS = [
    {
        "category": "technology",
        "title": "äººå·¥æ™ºèƒ½åœ¨åŒ»ç–—è¯Šæ–­ä¸­çš„çªç ´æ€§è¿›å±•",
        "prompt": "å†™ä¸€ç¯‡å…³äºäººå·¥æ™ºèƒ½åœ¨åŒ»ç–—è¯Šæ–­é¢†åŸŸæœ€æ–°çªç ´çš„æ–°é—»æ–‡ç« ã€‚å†…å®¹åº”åŒ…å«ï¼šå…·ä½“çš„æŠ€æœ¯çªç ´ã€ç ”ç©¶æœºæ„ã€ä¸´åºŠåº”ç”¨æ¡ˆä¾‹ã€ä¸“å®¶è§‚ç‚¹ã€æœªæ¥å±•æœ›ã€‚æ–‡ç« é•¿åº¦çº¦800-1000å­—ï¼Œè¯­è¨€ä¸“ä¸šä½†æ˜“æ‡‚ã€‚"
    },
    {
        "category": "technology", 
        "title": "é‡å­è®¡ç®—åœ¨é‡‘èé£é™©åˆ†æä¸­çš„åº”ç”¨ç ”ç©¶",
        "prompt": "æ’°å†™ä¸€ç¯‡å…³äºé‡å­è®¡ç®—æŠ€æœ¯åœ¨é‡‘èé£é™©åˆ†æå’ŒæŠ•èµ„ç»„åˆä¼˜åŒ–ä¸­åº”ç”¨çš„æ·±åº¦æŠ¥é“ã€‚åŒ…å«æŠ€æœ¯åŸç†ã€å®é™…æ¡ˆä¾‹ã€ä¸šç•Œååº”ã€ç›‘ç®¡è€ƒè™‘ã€‚çº¦900å­—ã€‚"
    },
    {
        "category": "technology",
        "title": "5Gç½‘ç»œæ¨åŠ¨æ™ºæ…§åŸå¸‚åŸºç¡€è®¾æ–½å‡çº§",
        "prompt": "æŠ¥é“5GæŠ€æœ¯å¦‚ä½•æ¨åŠ¨æ™ºæ…§åŸå¸‚å»ºè®¾ï¼ŒåŒ…æ‹¬äº¤é€šç®¡ç†ã€ç¯å¢ƒç›‘æµ‹ã€å…¬å…±å®‰å…¨ç­‰æ–¹é¢çš„åˆ›æ–°åº”ç”¨ã€‚æåŠå…·ä½“åŸå¸‚æ¡ˆä¾‹å’ŒæŠ€æœ¯ç»†èŠ‚ã€‚800-1000å­—ã€‚"
    },
    {
        "category": "finance",
        "title": "å¤®è¡Œæ•°å­—è´§å¸è¯•ç‚¹é¡¹ç›®æœ€æ–°è¿›å±•åˆ†æ",
        "prompt": "åˆ†æå…¨çƒä¸»è¦å¤®è¡Œæ•°å­—è´§å¸ï¼ˆCBDCï¼‰çš„è¯•ç‚¹é¡¹ç›®ç°çŠ¶ï¼ŒåŒ…æ‹¬ä¸­å›½æ•°å­—äººæ°‘å¸ã€æ¬§æ´²æ•°å­—æ¬§å…ƒç­‰ã€‚æ¶µç›–æŠ€æœ¯æ¶æ„ã€æ”¿ç­–å½±å“ã€å¸‚åœºååº”ã€‚çº¦900å­—ã€‚"
    },
    {
        "category": "finance",
        "title": "ESGæŠ•èµ„ç†å¿µé‡å¡‘å…¨çƒèµ„æœ¬å¸‚åœºæ ¼å±€", 
        "prompt": "æ·±åº¦åˆ†æESGï¼ˆç¯å¢ƒã€ç¤¾ä¼šã€æ²»ç†ï¼‰æŠ•èµ„ç†å¿µå¯¹å…¨çƒèµ„æœ¬å¸‚åœºçš„å½±å“ï¼ŒåŒ…æ‹¬æŠ•èµ„ç­–ç•¥å˜åŒ–ã€ä¼ä¸šä¼°å€¼é‡æ„ã€ç›‘ç®¡æ”¿ç­–è¶‹åŠ¿ã€‚800-1000å­—ã€‚"
    },
    {
        "category": "finance",
        "title": "åŠ å¯†è´§å¸å¸‚åœºç›‘ç®¡æ¡†æ¶é€æ­¥å®Œå–„",
        "prompt": "æŠ¥é“å„å›½åŠ å¯†è´§å¸ç›‘ç®¡æ”¿ç­–çš„æœ€æ–°å‘å±•ï¼Œåˆ†æç›‘ç®¡æ¡†æ¶å¯¹å¸‚åœºçš„å½±å“ï¼ŒåŒ…æ‹¬åˆè§„è¦æ±‚ã€æœºæ„å‚ä¸ã€æŠ€æœ¯åˆ›æ–°ç­‰æ–¹é¢ã€‚çº¦900å­—ã€‚"
    },
    {
        "category": "geopolitics",
        "title": "ä¸­ç¾ç§‘æŠ€ç«äº‰å¯¹å…¨çƒä¾›åº”é“¾çš„æ·±å±‚å½±å“",
        "prompt": "åˆ†æä¸­ç¾åœ¨åŠå¯¼ä½“ã€äººå·¥æ™ºèƒ½ç­‰å…³é”®æŠ€æœ¯é¢†åŸŸçš„ç«äº‰å¦‚ä½•é‡å¡‘å…¨çƒä¾›åº”é“¾æ ¼å±€ï¼ŒåŒ…æ‹¬äº§ä¸šè½¬ç§»ã€æŠ€æœ¯æ ‡å‡†ã€å›½é™…åˆä½œç­‰ã€‚800-1000å­—ã€‚"
    },
    {
        "category": "geopolitics", 
        "title": "æ¬§ç›Ÿæ•°å­—ä¸»æƒæˆ˜ç•¥çš„å…¨çƒå½±å“ä¸æŒ‘æˆ˜",
        "prompt": "æ·±åº¦è§£ææ¬§ç›Ÿæ•°å­—ä¸»æƒæˆ˜ç•¥çš„æ ¸å¿ƒå†…å®¹ã€å®æ–½è¿›å±•åŠå…¶å¯¹å…¨çƒæ•°å­—ç»æµæ²»ç†çš„å½±å“ï¼ŒåŒ…æ‹¬æ•°æ®ä¿æŠ¤ã€æŠ€æœ¯è‡ªä¸»ã€å›½é™…åˆä½œç­‰æ–¹é¢ã€‚çº¦900å­—ã€‚"
    },
    {
        "category": "geopolitics",
        "title": "æ–°å…´å¸‚åœºå›½å®¶åœ¨å…¨çƒæ²»ç†ä¸­çš„ä½œç”¨å¢å¼º",
        "prompt": "åˆ†æBRICSç­‰æ–°å…´å¸‚åœºå›½å®¶åœ¨å›½é™…é‡‘èä½“ç³»ã€æ°”å€™æ²»ç†ã€æ•°å­—ç»æµç­‰é¢†åŸŸå‘æŒ¥çš„é‡è¦ä½œç”¨åŠå…¶å¯¹ç°æœ‰å›½é™…ç§©åºçš„å½±å“ã€‚800-1000å­—ã€‚"
    },
    {
        "category": "environment",
        "title": "ç¢³ä¸­å’Œç›®æ ‡æ¨åŠ¨æ¸…æ´èƒ½æºæŠ€æœ¯åˆ›æ–°åŠ é€Ÿ",
        "prompt": "æŠ¥é“å…¨çƒç¢³ä¸­å’Œæ‰¿è¯ºå¦‚ä½•å‚¬ç”Ÿæ¸…æ´èƒ½æºæŠ€æœ¯çš„é‡å¤§çªç ´ï¼ŒåŒ…æ‹¬å‚¨èƒ½æŠ€æœ¯ã€æ°¢èƒ½å‘å±•ã€ç¢³æ•è·ç­‰åˆ›æ–°é¢†åŸŸã€‚æ¶µç›–æŠ€æœ¯è¿›å±•å’Œå•†ä¸šåŒ–å‰æ™¯ã€‚çº¦900å­—ã€‚"
    },
    {
        "category": "environment",
        "title": "ç”Ÿç‰©å¤šæ ·æ€§ä¿æŠ¤çš„ç§‘æŠ€åˆ›æ–°ä¸æ”¿ç­–åè°ƒ",
        "prompt": "åˆ†æç§‘æŠ€åˆ›æ–°åœ¨ç”Ÿç‰©å¤šæ ·æ€§ä¿æŠ¤ä¸­çš„åº”ç”¨ï¼ŒåŒ…æ‹¬AIç›‘æµ‹æŠ€æœ¯ã€åŸºå› ä¿æŠ¤æŠ€æœ¯ã€ç”Ÿæ€ç³»ç»Ÿæ¢å¤ç­‰ï¼Œä»¥åŠå›½é™…æ”¿ç­–åè°ƒæœºåˆ¶ã€‚800-1000å­—ã€‚"
    },
    {
        "category": "environment", 
        "title": "æç«¯æ°”å€™äº‹ä»¶é¢‘å‘å‡¸æ˜¾é€‚åº”æ€§æ²»ç†ç´§è¿«æ€§",
        "prompt": "æ·±åº¦æŠ¥é“è¿‘æœŸå…¨çƒæç«¯æ°”å€™äº‹ä»¶çš„å½±å“ï¼Œåˆ†ææ°”å€™é€‚åº”æ€§æ²»ç†çš„åˆ›æ–°å®è·µï¼ŒåŒ…æ‹¬åŸå¸‚éŸ§æ€§å»ºè®¾ã€ç¾å®³é¢„è­¦ç³»ç»Ÿã€å›½é™…åˆä½œæœºåˆ¶ã€‚çº¦900å­—ã€‚"
    }
]

class MockArticleGenerator:
    def __init__(self, base_url: str, api_token: str):
        self.base_url = base_url.rstrip('/')
        self.api_token = api_token
        self.headers = {
            'Content-Type': 'application/json'
        }
    
    async def generate_article_content(self, title: str, prompt: str) -> str:
        """ä½¿ç”¨AI Workerç”Ÿæˆæ–‡ç« å†…å®¹"""
        
        # æ„å»ºæ–‡ç« åˆ†æè¯·æ±‚ - ä½¿ç”¨meridianä¸“ç”¨ç«¯ç‚¹
        article_request = {
            "title": title,
            "content": f"{prompt}\n\nè¯·ä¸ºæ ‡é¢˜'{title}'ç”Ÿæˆä¸€ç¯‡å®Œæ•´çš„æ–°é—»æ–‡ç« ã€‚",
        }
        
        async with httpx.AsyncClient(timeout=60) as client:
            try:
                response = await client.post(
                    f"{self.base_url}/meridian/article/analyze",
                    json=article_request,
                    headers=self.headers
                )
                
                if response.status_code == 200:
                    result = response.json()
                    print(f"   ğŸ“¡ APIå“åº”: {response.status_code}")
                    
                    # æ£€æŸ¥å“åº”æ ¼å¼
                    if result.get('success') and 'data' in result:
                        # ä»åˆ†æç»“æœæ„å»ºæ–‡ç« å†…å®¹
                        analysis = result['data']
                        
                        # æ„å»ºç®€å•çš„æ–‡ç« å†…å®¹
                        content_parts = []
                        content_parts.append(f"# {title}\n")
                        
                        if analysis.get('event_summary_points'):
                            content_parts.append("## æ ¸å¿ƒè¦ç‚¹")
                            for point in analysis['event_summary_points'][:3]:
                                content_parts.append(f"- {point}")
                            content_parts.append("")
                        
                        if analysis.get('thematic_keywords'):
                            keywords = ', '.join(analysis['thematic_keywords'][:5])
                            content_parts.append(f"**å…³é”®è¯**: {keywords}\n")
                        
                        # æ·»åŠ åŸºç¡€å†…å®¹
                        content_parts.append("è¿™æ˜¯ä¸€ç¯‡å…³äºä»¥ä¸Šä¸»é¢˜çš„æ·±åº¦åˆ†ææ–‡ç« ã€‚æœ¬æ–‡æ¢è®¨äº†ç›¸å…³çš„æŠ€æœ¯å‘å±•ã€å¸‚åœºè¶‹åŠ¿å’Œç¤¾ä¼šå½±å“ã€‚")
                        content_parts.append("")
                        content_parts.append("## è¯¦ç»†åˆ†æ")
                        content_parts.append("éšç€ç§‘æŠ€çš„å¿«é€Ÿå‘å±•å’Œå…¨çƒåŒ–çš„æ·±å…¥æ¨è¿›ï¼Œè¿™ä¸€é¢†åŸŸæ­£åœ¨ç»å†å‰æ‰€æœªæœ‰çš„å˜é©ã€‚")
                        content_parts.append("")
                        content_parts.append("## æœªæ¥å±•æœ›")
                        content_parts.append("å±•æœ›æœªæ¥ï¼Œè¿™ä¸€è¶‹åŠ¿å°†ç»§ç»­å½±å“ç›¸å…³è¡Œä¸šçš„å‘å±•æ–¹å‘ï¼Œå€¼å¾—æŒç»­å…³æ³¨ã€‚")
                        
                        if analysis.get('key_entities'):
                            entities = ', '.join(analysis['key_entities'][:3])
                            content_parts.append(f"\n**ç›¸å…³å®ä½“**: {entities}")
                        
                        generated_content = '\n'.join(content_parts)
                        return generated_content
                    else:
                        print(f"   âŒ å“åº”æ ¼å¼é”™è¯¯: {result}")
                        return None
                else:
                    print(f"   âŒ HTTPé”™è¯¯ {response.status_code}: {response.text}")
                    return None
                    
            except Exception as e:
                print(f"   âŒ è¯·æ±‚å¼‚å¸¸: {e}")
                return None
    
    async def generate_all_articles(self) -> List[Dict[str, Any]]:
        """ç”Ÿæˆæ‰€æœ‰æ¨¡æ‹Ÿæ–‡ç« """
        
        print(f"ğŸš€ å¼€å§‹ç”Ÿæˆ {len(ARTICLE_TOPICS)} ç¯‡æ¨¡æ‹Ÿæ–‡ç« ...")
        print(f"ğŸ“¡ AI Worker: {self.base_url}")
        
        articles = []
        
        for i, topic in enumerate(ARTICLE_TOPICS, 1):
            print(f"\nğŸ“ [{i}/{len(ARTICLE_TOPICS)}] ç”Ÿæˆæ–‡ç« : {topic['title']}")
            
            content = await self.generate_article_content(
                topic['title'], 
                topic['prompt']
            )
            
            if content:
                article = {
                    "id": i,
                    "title": topic['title'],
                    "content": content,
                    "category": topic['category'],
                    "generated_at": time.time()
                }
                articles.append(article)
                print(f"   âœ… æˆåŠŸç”Ÿæˆ ({len(content)} å­—ç¬¦)")
            else:
                print(f"   âŒ ç”Ÿæˆå¤±è´¥")
            
            # é¿å…è¯·æ±‚è¿‡äºé¢‘ç¹
            await asyncio.sleep(2)
        
        return articles
    
    async def save_articles(self, articles: List[Dict[str, Any]], filename: str = "mock_articles.json"):
        """ä¿å­˜ç”Ÿæˆçš„æ–‡ç« åˆ°æ–‡ä»¶"""
        
        output_data = {
            "generated_at": time.time(),
            "total_articles": len(articles),
            "categories": list(set(article['category'] for article in articles)),
            "articles": articles
        }
        
        with open(filename, 'w', encoding='utf-8') as f:
            json.dump(output_data, f, ensure_ascii=False, indent=2)
        
        print(f"\nğŸ’¾ å·²ä¿å­˜ {len(articles)} ç¯‡æ–‡ç« åˆ° {filename}")
        
        # ç”Ÿæˆç»Ÿè®¡ä¿¡æ¯
        category_stats = {}
        total_length = 0
        
        for article in articles:
            cat = article['category']
            category_stats[cat] = category_stats.get(cat, 0) + 1
            total_length += len(article['content'])
        
        print(f"ğŸ“Š ç»Ÿè®¡ä¿¡æ¯:")
        print(f"   - æ€»æ–‡ç« æ•°: {len(articles)}")
        print(f"   - æ€»å­—ç¬¦æ•°: {total_length:,}")
        print(f"   - å¹³å‡é•¿åº¦: {total_length // len(articles):,} å­—ç¬¦")
        
        for cat, count in category_stats.items():
            print(f"   - {cat}: {count} ç¯‡")

async def main():
    """ä¸»å‡½æ•°"""
    print("ğŸ¯ Meridian æ¨¡æ‹Ÿæ–‡ç« ç”Ÿæˆå™¨")
    print("=" * 50)
    
    # åˆå§‹åŒ–ç”Ÿæˆå™¨
    generator = MockArticleGenerator(AI_WORKER_BASE_URL, API_TOKEN)
    
    # ç”Ÿæˆæ–‡ç« 
    articles = await generator.generate_all_articles()
    
    if articles:
        # ä¿å­˜åˆ°æ–‡ä»¶
        await generator.save_articles(articles)
        
        print(f"\nğŸ‰ å®Œæˆï¼ç”Ÿæˆäº† {len(articles)} ç¯‡æ¨¡æ‹Ÿæ–‡ç« ")
        print("ğŸ’¡ ç°åœ¨å¯ä»¥ä½¿ç”¨è¿™äº›æ–‡ç« æµ‹è¯•MLæœåŠ¡çš„èšç±»åŠŸèƒ½")
    else:
        print("\nğŸ˜ æ²¡æœ‰æˆåŠŸç”Ÿæˆä»»ä½•æ–‡ç« ")

if __name__ == "__main__":
    asyncio.run(main()) 