#!/usr/bin/env python3
"""
æœ¬åœ°æµ‹è¯•è„šæœ¬ - æµ‹è¯•MLæœåŠ¡çš„å„é¡¹åŠŸèƒ½
"""

import asyncio
import json
import time
from typing import List

import httpx


class MLServiceTester:
    """MLæœåŠ¡æµ‹è¯•å™¨"""
    
    def __init__(self, base_url: str = "http://localhost:8081", api_token: str = "dev-token-123"):
        self.base_url = base_url
        self.headers = {"X-API-Token": api_token}
        
    async def test_health(self):
        """æµ‹è¯•å¥åº·æ£€æŸ¥"""
        print("ğŸ” æµ‹è¯•å¥åº·æ£€æŸ¥...")
        
        async with httpx.AsyncClient() as client:
            response = await client.get(f"{self.base_url}/health")
            
            if response.status_code == 200:
                health_data = response.json()
                print("âœ… å¥åº·æ£€æŸ¥é€šè¿‡")
                print(f"   çŠ¶æ€: {health_data['status']}")
                print(f"   åµŒå…¥æ¨¡å‹: {health_data['embedding_model']}")
                print(f"   èšç±»å¯ç”¨: {health_data['clustering_available']}")
                print(f"   ä¼˜åŒ–å¯ç”¨: {health_data['optimization_available']}")
                
                if not health_data['clustering_available']:
                    print("âš ï¸  è­¦å‘Š: èšç±»åŠŸèƒ½ä¸å¯ç”¨")
                    
                return health_data['clustering_available']
            else:
                print(f"âŒ å¥åº·æ£€æŸ¥å¤±è´¥: {response.status_code}")
                return False
    
    async def test_embeddings(self, texts: List[str]):
        """æµ‹è¯•åµŒå…¥ç”Ÿæˆ"""
        print(f"\nğŸ§® æµ‹è¯•åµŒå…¥ç”Ÿæˆ ({len(texts)} ä¸ªæ–‡æœ¬)...")
        
        payload = {"texts": texts}
        
        async with httpx.AsyncClient(timeout=60) as client:
            start_time = time.time()
            response = await client.post(
                f"{self.base_url}/embeddings",
                json=payload,
                headers=self.headers
            )
            processing_time = time.time() - start_time
            
            if response.status_code == 200:
                data = response.json()
                embeddings = data['embeddings']
                print(f"âœ… åµŒå…¥ç”ŸæˆæˆåŠŸ")
                print(f"   æ¨¡å‹: {data['model_name']}")
                print(f"   åµŒå…¥ç»´åº¦: {len(embeddings[0])}ç»´")
                print(f"   å¤„ç†æ—¶é—´: {processing_time:.2f}ç§’")
                return embeddings
            else:
                print(f"âŒ åµŒå…¥ç”Ÿæˆå¤±è´¥: {response.status_code}")
                print(f"   é”™è¯¯: {response.text}")
                return None
    
    async def test_clustering(self, texts: List[str]):
        """æµ‹è¯•æ ‡å‡†èšç±»åŠŸèƒ½"""
        print(f"\nğŸ”— æµ‹è¯•æ ‡å‡†èšç±»åŠŸèƒ½ ({len(texts)} ä¸ªæ–‡æœ¬)...")
        
        payload = {
            "texts": texts,
            "config": {
                "umap_n_components": 10,  # æ›´æ–°ä¸ºreportV5é»˜è®¤å€¼
                "umap_n_neighbors": min(15, len(texts) - 1),
                "umap_min_dist": 0.0,  # ä½¿ç”¨reportV5çš„å€¼
                "hdbscan_min_cluster_size": min(5, len(texts) // 3),
                "hdbscan_min_samples": 3,
                "hdbscan_cluster_selection_epsilon": 0.0,
                "normalize_embeddings": True
            },
            "return_embeddings": False,
            "return_reduced_embeddings": True
        }
        
        async with httpx.AsyncClient(timeout=120) as client:
            start_time = time.time()
            response = await client.post(
                f"{self.base_url}/clustering",
                json=payload,
                headers=self.headers
            )
            processing_time = time.time() - start_time
            
            if response.status_code == 200:
                data = response.json()
                stats = data['clustering_stats']
                print(f"âœ… æ ‡å‡†èšç±»æˆåŠŸ")
                print(f"   ç°‡æ•°é‡: {stats['n_clusters']}")
                print(f"   å¼‚å¸¸ç‚¹: {stats['n_outliers']} ({stats['outlier_ratio']:.1%})")
                print(f"   ç°‡å¤§å°: {stats['cluster_sizes']}")
                if stats['dbcv_score'] is not None:
                    print(f"   DBCVåˆ†æ•°: {stats['dbcv_score']:.4f}")
                print(f"   å¤„ç†æ—¶é—´: {processing_time:.2f}ç§’")
                
                # æ˜¾ç¤ºç°‡å†…å®¹ç¤ºä¾‹
                if 'cluster_content' in data and data['cluster_content']:
                    print(f"   ç°‡å†…å®¹ç¤ºä¾‹:")
                    for cluster_id, content in data['cluster_content'].items():
                        print(f"     ç°‡{cluster_id}: {len(content)}ä¸ªæ–‡æœ¬")
                        for text in content[:2]:  # åªæ˜¾ç¤ºå‰2ä¸ª
                            print(f"       - {text[:80]}...")
                
                return data
            else:
                print(f"âŒ æ ‡å‡†èšç±»å¤±è´¥: {response.status_code}")
                print(f"   é”™è¯¯: {response.text}")
                return None

    async def test_optimized_clustering(self, texts: List[str]):
        """æµ‹è¯•ä¼˜åŒ–èšç±»åŠŸèƒ½"""
        print(f"\nğŸ¯ æµ‹è¯•ä¼˜åŒ–èšç±»åŠŸèƒ½ ({len(texts)} ä¸ªæ–‡æœ¬)...")
        
        # ä¸ºäº†æµ‹è¯•é€Ÿåº¦ï¼Œä½¿ç”¨è¾ƒå°çš„å‚æ•°ç½‘æ ¼
        payload = {
            "texts": texts,
            "grid_config": {
                "umap_n_neighbors": [10, 15, 20],  # å‡å°‘ç»„åˆæ•°
                "umap_n_components": 10,
                "umap_min_dist": 0.0,
                "hdbscan_min_cluster_size": [5, 8],  # å‡å°‘ç»„åˆæ•°
                "hdbscan_min_samples": [2, 3],
                "hdbscan_epsilon": [0.1, 0.2]  # å‡å°‘ç»„åˆæ•°
            },
            "return_embeddings": False,
            "return_reduced_embeddings": True
        }
        
        async with httpx.AsyncClient(timeout=300) as client:  # å¢åŠ è¶…æ—¶æ—¶é—´
            start_time = time.time()
            response = await client.post(
                f"{self.base_url}/clustering/optimized",
                json=payload,
                headers=self.headers
            )
            processing_time = time.time() - start_time
            
            if response.status_code == 200:
                data = response.json()
                stats = data['clustering_stats']
                optimization = data['optimization']
                
                print(f"âœ… ä¼˜åŒ–èšç±»æˆåŠŸ")
                print(f"   ç°‡æ•°é‡: {stats['n_clusters']}")
                print(f"   å¼‚å¸¸ç‚¹: {stats['n_outliers']} ({stats['outlier_ratio']:.1%})")
                print(f"   ç°‡å¤§å°: {stats['cluster_sizes']}")
                if stats['dbcv_score'] is not None:
                    print(f"   DBCVåˆ†æ•°: {stats['dbcv_score']:.4f}")
                print(f"   å¤„ç†æ—¶é—´: {processing_time:.2f}ç§’")
                
                if optimization['used']:
                    print(f"   âœ¨ å‚æ•°ä¼˜åŒ–ç»“æœ:")
                    if optimization['best_dbcv_score'] is not None:
                        print(f"     æœ€ä½³DBCVåˆ†æ•°: {optimization['best_dbcv_score']:.4f}")
                    if optimization['best_params']:
                        umap_params = optimization['best_params']['umap']
                        hdbscan_params = optimization['best_params']['hdbscan']
                        print(f"     æœ€ä½³UMAPå‚æ•°: n_neighbors={umap_params['n_neighbors']}")
                        print(f"     æœ€ä½³HDBSCANå‚æ•°: min_cluster_size={hdbscan_params['min_cluster_size']}, "
                              f"min_samples={hdbscan_params['min_samples']}, epsilon={hdbscan_params['epsilon']}")
                
                return data
            else:
                print(f"âŒ ä¼˜åŒ–èšç±»å¤±è´¥: {response.status_code}")
                print(f"   é”™è¯¯: {response.text}")
                return None
    
    async def test_full_pipeline(self, texts: List[str]):
        """æµ‹è¯•å®Œæ•´æµæ°´çº¿ï¼ˆä¸å¸¦ä¼˜åŒ–ï¼‰"""
        print(f"\nğŸš€ æµ‹è¯•å®Œæ•´æµæ°´çº¿ ({len(texts)} ä¸ªæ–‡æœ¬)...")
        
        payload = {
            "texts": texts,
            "clustering_config": {
                "umap_n_components": 10,
                "umap_n_neighbors": min(15, len(texts) - 1),
                "umap_min_dist": 0.0,
                "hdbscan_min_cluster_size": min(5, len(texts) // 3),
                "hdbscan_min_samples": 3,
                "hdbscan_cluster_selection_epsilon": 0.0
            },
            "include_cluster_content": True,
            "content_top_n": 3,
            "use_optimization": False
        }
        
        async with httpx.AsyncClient(timeout=180) as client:
            start_time = time.time()
            response = await client.post(
                f"{self.base_url}/embeddings-and-clustering",
                json=payload,
                headers=self.headers
            )
            processing_time = time.time() - start_time
            
            if response.status_code == 200:
                data = response.json()
                clustering_result = data['clustering_result']
                stats = clustering_result['clustering_stats']
                
                print(f"âœ… å®Œæ•´æµæ°´çº¿æˆåŠŸ")
                print(f"   æ¨¡å‹: {data['model_name']}")
                print(f"   åµŒå…¥ç»´åº¦: {len(data['embeddings'][0])}ç»´")
                print(f"   ç°‡æ•°é‡: {stats['n_clusters']}")
                if stats['dbcv_score'] is not None:
                    print(f"   DBCVåˆ†æ•°: {stats['dbcv_score']:.4f}")
                print(f"   æœåŠ¡å™¨å¤„ç†æ—¶é—´: {data.get('processing_time', 0):.2f}ç§’")
                print(f"   æ€»è€—æ—¶: {processing_time:.2f}ç§’")
                
                return data
            else:
                print(f"âŒ å®Œæ•´æµæ°´çº¿å¤±è´¥: {response.status_code}")
                print(f"   é”™è¯¯: {response.text}")
                return None

    async def test_optimized_full_pipeline(self, texts: List[str]):
        """æµ‹è¯•ä¼˜åŒ–ç‰ˆå®Œæ•´æµæ°´çº¿"""
        print(f"\nğŸ¯ğŸš€ æµ‹è¯•ä¼˜åŒ–ç‰ˆå®Œæ•´æµæ°´çº¿ ({len(texts)} ä¸ªæ–‡æœ¬)...")
        
        payload = {
            "texts": texts,
            "grid_config": {
                "umap_n_neighbors": [10, 15],  # å‡å°‘å‚æ•°ç»„åˆä»¥åŠ å¿«æµ‹è¯•
                "umap_n_components": 10,
                "umap_min_dist": 0.0,
                "hdbscan_min_cluster_size": [5, 8],
                "hdbscan_min_samples": [2, 3],
                "hdbscan_epsilon": [0.1, 0.2]
            },
            "include_cluster_content": True,
            "content_top_n": 3,
            "use_optimization": True
        }
        
        async with httpx.AsyncClient(timeout=300) as client:  # å¢åŠ è¶…æ—¶æ—¶é—´
            start_time = time.time()
            response = await client.post(
                f"{self.base_url}/embeddings-and-clustering",
                json=payload,
                headers=self.headers
            )
            processing_time = time.time() - start_time
            
            if response.status_code == 200:
                data = response.json()
                clustering_result = data['clustering_result']
                stats = clustering_result['clustering_stats']
                optimization = clustering_result['optimization']
                
                print(f"âœ… ä¼˜åŒ–ç‰ˆå®Œæ•´æµæ°´çº¿æˆåŠŸ")
                print(f"   æ¨¡å‹: {data['model_name']}")
                print(f"   åµŒå…¥ç»´åº¦: {len(data['embeddings'][0])}ç»´")
                print(f"   ç°‡æ•°é‡: {stats['n_clusters']}")
                if stats['dbcv_score'] is not None:
                    print(f"   DBCVåˆ†æ•°: {stats['dbcv_score']:.4f}")
                print(f"   æœåŠ¡å™¨å¤„ç†æ—¶é—´: {data.get('processing_time', 0):.2f}ç§’")
                print(f"   æ€»è€—æ—¶: {processing_time:.2f}ç§’")
                
                if optimization['used'] and optimization['best_dbcv_score'] is not None:
                    print(f"   ğŸ¯ ä¼˜åŒ–ç»“æœ: DBCVåˆ†æ•°={optimization['best_dbcv_score']:.4f}")
                
                return data
            else:
                print(f"âŒ ä¼˜åŒ–ç‰ˆå®Œæ•´æµæ°´çº¿å¤±è´¥: {response.status_code}")
                print(f"   é”™è¯¯: {response.text}")
                return None


# æµ‹è¯•æ•°æ® - å¢åŠ ä¸€äº›æ–‡æœ¬ä»¥ä¾¿æ›´å¥½åœ°æµ‹è¯•èšç±»
TEST_TEXTS = [
    # ç§‘æŠ€æ–°é—» - AI/ML
    "OpenAIå‘å¸ƒäº†æ–°çš„GPT-4æ¨¡å‹ï¼Œå…·æœ‰æ›´å¼ºå¤§çš„å¤šæ¨¡æ€èƒ½åŠ›",
    "Googleæ¨å‡ºæ–°çš„AIæœç´¢ç®—æ³•ï¼Œå¤§å¹…æå‡æœç´¢å‡†ç¡®æ€§",
    "Metaå‘å¸ƒVRå¤´æ˜¾æ–°å“ï¼Œæ”¯æŒå…ˆè¿›çš„AIæ··åˆç°å®åŠŸèƒ½",
    "ç™¾åº¦å‘å¸ƒæ–‡å¿ƒä¸€è¨€å¤§æ¨¡å‹ï¼ŒæŒ‘æˆ˜ChatGPTåœ¨ä¸­æ–‡å¸‚åœºçš„åœ°ä½",
    "è‹±ä¼Ÿè¾¾å‘å¸ƒæ–°ä¸€ä»£AIèŠ¯ç‰‡ï¼Œæ€§èƒ½æå‡300%",
    
    # ç§‘æŠ€æ–°é—» - æ¶ˆè´¹ç”µå­
    "è‹¹æœå…¬å¸å‘å¸ƒæœ€æ–°iPhone 15ï¼Œæ­è½½å…ˆè¿›çš„A17èŠ¯ç‰‡",
    "ç‰¹æ–¯æ‹‰å‘å¸ƒè‡ªåŠ¨é©¾é©¶è½¯ä»¶æ›´æ–°ï¼Œæå‡å®‰å…¨æ€§èƒ½",
    "åä¸ºå‘å¸ƒMate 60ç³»åˆ—ï¼Œæ­è½½è‡ªç ”5GèŠ¯ç‰‡",
    "å°ç±³å‘å¸ƒæ–°æ¬¾æ™ºèƒ½æ‰‹æœºï¼Œå”®ä»·ä»…999å…ƒ",
    "ä¸‰æ˜Ÿå±•ç¤ºæŠ˜å å±æŠ€æœ¯æ–°çªç ´ï¼Œå±å¹•å¯æŠ˜å ä¸‡æ¬¡",
    
    # ç»æµæ–°é—» - è´§å¸æ”¿ç­–
    "ç¾è”å‚¨å®£å¸ƒç»´æŒåˆ©ç‡ä¸å˜ï¼Œå¸‚åœºååº”å¹³ç¨³",
    "æ¬§æ´²å¤®è¡Œè€ƒè™‘è°ƒæ•´è´§å¸æ”¿ç­–åº”å¯¹æŒç»­é€šèƒ€",
    "ä¸­å›½å¤®è¡Œä¸‹è°ƒå­˜æ¬¾å‡†å¤‡é‡‘ç‡ï¼Œé‡Šæ”¾æµåŠ¨æ€§",
    "æ—¥æœ¬å¤®è¡Œç»´æŒè¶…å®½æ¾è´§å¸æ”¿ç­–ç«‹åœº",
    "è‹±å›½å¤®è¡ŒåŠ æ¯25ä¸ªåŸºç‚¹åº”å¯¹é€šèƒ€å‹åŠ›",
    
    # ç»æµæ–°é—» - å¸‚åœºè¡¨ç°  
    "ä¸­å›½GDPå¢é•¿è¶…é¢„æœŸï¼Œç»æµå¤è‹åŠ¿å¤´è‰¯å¥½",
    "çŸ³æ²¹ä»·æ ¼å› åœ°ç¼˜æ”¿æ²»ç´§å¼ å±€åŠ¿ä¸Šæ¶¨5%",
    "æ¯”ç‰¹å¸ä»·æ ¼çªç ´65000ç¾å…ƒï¼Œåˆ›å†å²æ–°é«˜",
    "é»„é‡‘ä»·æ ¼å—é¿é™©æƒ…ç»ªæ¨åŠ¨æŒç»­ä¸Šæ¶¨",
    "ç¾è‚¡ä¸‰å¤§æŒ‡æ•°é›†ä½“æ”¶æ¶¨ï¼Œç§‘æŠ€è‚¡é¢†æ¶¨",
    
    # ä½“è‚²æ–°é—»
    "2024å·´é»å¥¥è¿ä¼šå¼€å¹•åœ¨å³ï¼Œå„å›½ä»£è¡¨å›¢é™†ç»­æŠµè¾¾",
    "NBAæ€»å†³èµ›è¿›å…¥ç™½çƒ­åŒ–é˜¶æ®µï¼ŒåŒæ–¹æˆ˜è‡³æŠ¢ä¸ƒ",
    "ä¸–ç•Œæ¯é¢„é€‰èµ›æ¿€æˆ˜æ­£é…£ï¼Œå¤šæ”¯å¼ºé˜Ÿå‡ºçº¿å½¢åŠ¿ä¸¥å³»",
    "ç½‘çƒå¤§æ»¡è´¯èµ›äº‹ç²¾å½©çº·å‘ˆï¼Œæ–°æ˜Ÿå´›èµ·æŒ‘æˆ˜è€å°†",
    "é©¬æ‹‰æ¾ä¸–ç•Œçºªå½•å†æ¬¡è¢«æ‰“ç ´ï¼Œäººç±»æé™ç»§ç»­çªç ´",
]


async def main():
    """ä¸»æµ‹è¯•å‡½æ•°"""
    print("ğŸ¤– Meridian ML Service æœ¬åœ°æµ‹è¯• (v0.3.0 - å‚æ•°ä¼˜åŒ–ç‰ˆ)")
    print("=" * 60)
    
    tester = MLServiceTester()
    
    # 1. å¥åº·æ£€æŸ¥
    clustering_available = await tester.test_health()
    
    if not clustering_available:
        print("\nâš ï¸  èšç±»åŠŸèƒ½ä¸å¯ç”¨ï¼Œè·³è¿‡èšç±»ç›¸å…³æµ‹è¯•")
        print("   å®‰è£…å‘½ä»¤: pip install umap-learn hdbscan scikit-learn")
        return
    
    # 2. æµ‹è¯•åµŒå…¥ç”Ÿæˆ
    await tester.test_embeddings(TEST_TEXTS[:5])
    
    # 3. æµ‹è¯•æ ‡å‡†èšç±»åŠŸèƒ½
    await tester.test_clustering(TEST_TEXTS)
    
    # 4. æµ‹è¯•ä¼˜åŒ–èšç±»åŠŸèƒ½
    print(f"\nâ° æ³¨æ„ï¼šå‚æ•°ä¼˜åŒ–éœ€è¦è¾ƒé•¿æ—¶é—´ï¼Œè¯·è€å¿ƒç­‰å¾…...")
    await tester.test_optimized_clustering(TEST_TEXTS)
    
    # 5. æµ‹è¯•æ ‡å‡†å®Œæ•´æµæ°´çº¿
    await tester.test_full_pipeline(TEST_TEXTS)
    
    # 6. æµ‹è¯•ä¼˜åŒ–ç‰ˆå®Œæ•´æµæ°´çº¿
    print(f"\nâ° æ³¨æ„ï¼šä¼˜åŒ–ç‰ˆæµæ°´çº¿éœ€è¦æ›´é•¿æ—¶é—´...")
    await tester.test_optimized_full_pipeline(TEST_TEXTS)
    
    print("\nğŸ‰ æ‰€æœ‰æµ‹è¯•å®Œæˆ!")
    print("\nğŸ“Š æµ‹è¯•æ€»ç»“:")
    print("   âœ… åµŒå…¥ç”Ÿæˆ: åŸºç¡€åŠŸèƒ½")
    print("   âœ… æ ‡å‡†èšç±»: ä½¿ç”¨å›ºå®šå‚æ•°")
    print("   âœ… ä¼˜åŒ–èšç±»: ç½‘æ ¼æœç´¢æœ€ä½³å‚æ•°")
    print("   âœ… å®Œæ•´æµæ°´çº¿: ç«¯åˆ°ç«¯å¤„ç†")
    print("   âœ… ä¼˜åŒ–æµæ°´çº¿: ç«¯åˆ°ç«¯ + å‚æ•°ä¼˜åŒ–")


if __name__ == "__main__":
    asyncio.run(main()) 